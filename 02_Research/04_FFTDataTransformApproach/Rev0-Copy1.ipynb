{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_learn_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainwave Frequencies:\n",
    "Gamma, 30 to 50 Hz.  \n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n",
    "Delta, 0.1 to 4 Hz.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Bin Size: \n",
    "https://stackoverflow.com/questions/25735153/plotting-a-fast-fourier-transform-in-python  \n",
    "(Search for 'bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An EEG processing library:  \n",
    "https://github.com/pbashivan/EEGLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds \n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = 100#Fs*frame_duration\n",
    "    frames = []\n",
    "    #steps = make_steps(len(df),frame_duration,overlap)\n",
    "\n",
    "    frame = []\n",
    "    for channel in df.columns:\n",
    "        snippet = np.array(df.loc[:,int(channel)])\n",
    "        f,Y =  get_fft(snippet)\n",
    "        theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "        frame.append([theta, alpha, beta])\n",
    "    frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_pipeline(df,image_size):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "    \n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = 100#Fs * frame_duration\n",
    "    \n",
    "\n",
    "\n",
    "    X_0 = make_frames(df,frame_duration)\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    X_1 = X_0.reshape(len(X_0),14*3)\n",
    "\n",
    "    images = gen_images(np.array(locs_2d),X_1, image_size, normalize=True)\n",
    "    images = np.swapaxes(images, 1, 3) \n",
    "    X = images\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_train = pd.DataFrame(genfromtxt('data/data_0.csv', delimiter=',')).iloc[0:180000]\n",
    "df_0_test = pd.DataFrame(genfromtxt('data/data_0.csv', delimiter=',')).iloc[180000:]\n",
    "df_1_train = pd.DataFrame(genfromtxt('data/data_1.csv', delimiter=',')).iloc[0:175000]\n",
    "df_1_test = pd.DataFrame(genfromtxt('data/data_1.csv', delimiter=',')).iloc[175000:]\n",
    "df_0_train.to_csv('data/data_0_train.csv', index = False)\n",
    "df_0_test.to_csv('data/data_0_test.csv', index = False)\n",
    "df_1_train.to_csv('data/data_1_train.csv', index = False)\n",
    "df_1_test.to_csv('data/data_1_test.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating 1/1\r",
      "\r"
     ]
    }
   ],
   "source": [
    "file_names = ['data/data_0.csv',\n",
    "              'data/data_1.csv']\n",
    "labels = [1,0]\n",
    "image_size = 28\n",
    "frame_duration = 0.78\n",
    "overlap = 0.0\n",
    "X = make_data_pipeline(df,image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3d861059fa55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x251edd7a148>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600,)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3600, 28, 28, 3)\n",
      "3600 train samples\n",
      "401 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0040877517"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 360 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 568us/step - loss: 0.6418 - categorical_accuracy: 0.6179 - val_loss: 0.5686 - val_categorical_accuracy: 0.7917\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.4686 - categorical_accuracy: 0.8519 - val_loss: 0.5229 - val_categorical_accuracy: 0.7444\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.3135 - categorical_accuracy: 0.9111 - val_loss: 0.7081 - val_categorical_accuracy: 0.6333\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.2245 - categorical_accuracy: 0.93 - 1s 429us/step - loss: 0.2243 - categorical_accuracy: 0.9352 - val_loss: 0.6886 - val_categorical_accuracy: 0.7139\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.1721 - categorical_accuracy: 0.9485 - val_loss: 0.5940 - val_categorical_accuracy: 0.7639\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.1410 - categorical_accuracy: 0.9562 - val_loss: 0.5830 - val_categorical_accuracy: 0.7889\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.1206 - categorical_accuracy: 0.9590 - val_loss: 0.7226 - val_categorical_accuracy: 0.7778\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.1053 - categorical_accuracy: 0.9648 - val_loss: 0.5769 - val_categorical_accuracy: 0.8056\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0971 - categorical_accuracy: 0.9682 - val_loss: 0.4325 - val_categorical_accuracy: 0.8694\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0905 - categorical_accuracy: 0.9688 - val_loss: 0.6035 - val_categorical_accuracy: 0.8111\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0794 - categorical_accuracy: 0.9738 - val_loss: 0.4265 - val_categorical_accuracy: 0.8750\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0741 - categorical_accuracy: 0.9744 - val_loss: 0.5347 - val_categorical_accuracy: 0.8306\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0683 - categorical_accuracy: 0.9793 - val_loss: 0.4404 - val_categorical_accuracy: 0.8611\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0695 - categorical_accuracy: 0.9799 - val_loss: 0.4004 - val_categorical_accuracy: 0.8778\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0651 - categorical_accuracy: 0.9796 - val_loss: 0.5105 - val_categorical_accuracy: 0.8333\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0604 - categorical_accuracy: 0.9796 - val_loss: 0.4509 - val_categorical_accuracy: 0.8861\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0604 - categorical_accuracy: 0.9806 - val_loss: 0.4366 - val_categorical_accuracy: 0.8722\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0541 - categorical_accuracy: 0.9827 - val_loss: 0.5106 - val_categorical_accuracy: 0.8611\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0529 - categorical_accuracy: 0.9836 - val_loss: 0.5958 - val_categorical_accuracy: 0.8444\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0529 - categorical_accuracy: 0.9843 - val_loss: 0.5802 - val_categorical_accuracy: 0.8611\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0499 - categorical_accuracy: 0.9843 - val_loss: 0.3949 - val_categorical_accuracy: 0.9111\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0478 - categorical_accuracy: 0.9852 - val_loss: 0.4863 - val_categorical_accuracy: 0.8889\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0453 - categorical_accuracy: 0.9870 - val_loss: 0.3400 - val_categorical_accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0455 - categorical_accuracy: 0.9858 - val_loss: 0.5515 - val_categorical_accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0422 - categorical_accuracy: 0.9877 - val_loss: 0.4772 - val_categorical_accuracy: 0.8972\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0425 - categorical_accuracy: 0.9864 - val_loss: 0.4985 - val_categorical_accuracy: 0.8833\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0423 - categorical_accuracy: 0.9877 - val_loss: 0.8388 - val_categorical_accuracy: 0.8472\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0400 - categorical_accuracy: 0.9895 - val_loss: 0.4520 - val_categorical_accuracy: 0.9222\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0374 - categorical_accuracy: 0.9886 - val_loss: 0.9884 - val_categorical_accuracy: 0.8389\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0374 - categorical_accuracy: 0.9898 - val_loss: 0.5830 - val_categorical_accuracy: 0.8889\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 571us/step - loss: 0.6136 - categorical_accuracy: 0.7068 - val_loss: 0.5222 - val_categorical_accuracy: 0.8061\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.4355 - categorical_accuracy: 0.8855 - val_loss: 0.7450 - val_categorical_accuracy: 0.5956\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.2864 - categorical_accuracy: 0.9265 - val_loss: 0.6226 - val_categorical_accuracy: 0.7230\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.2089 - categorical_accuracy: 0.9429 - val_loss: 0.4619 - val_categorical_accuracy: 0.8144\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.1703 - categorical_accuracy: 0.9500 - val_loss: 0.2929 - val_categorical_accuracy: 0.8864\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.1472 - categorical_accuracy: 0.9546 - val_loss: 0.6006 - val_categorical_accuracy: 0.8089\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.1266 - categorical_accuracy: 0.9590 - val_loss: 0.7259 - val_categorical_accuracy: 0.7867\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.1072 - categorical_accuracy: 0.9648 - val_loss: 0.4813 - val_categorical_accuracy: 0.8532\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0992 - categorical_accuracy: 0.9701 - val_loss: 0.5537 - val_categorical_accuracy: 0.8615\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0903 - categorical_accuracy: 0.9716 - val_loss: 0.5803 - val_categorical_accuracy: 0.8753\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0823 - categorical_accuracy: 0.9731 - val_loss: 0.7702 - val_categorical_accuracy: 0.8310\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0756 - categorical_accuracy: 0.9741 - val_loss: 0.4560 - val_categorical_accuracy: 0.9280\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0703 - categorical_accuracy: 0.9778 - val_loss: 0.9035 - val_categorical_accuracy: 0.8421\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0686 - categorical_accuracy: 0.9799 - val_loss: 0.6533 - val_categorical_accuracy: 0.8809\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0645 - categorical_accuracy: 0.9787 - val_loss: 0.6579 - val_categorical_accuracy: 0.8726\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0601 - categorical_accuracy: 0.9793 - val_loss: 0.9607 - val_categorical_accuracy: 0.8227\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0589 - categorical_accuracy: 0.9806 - val_loss: 1.0220 - val_categorical_accuracy: 0.8338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0517 - categorical_accuracy: 0.9806 - val_loss: 1.1239 - val_categorical_accuracy: 0.8172\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0551 - categorical_accuracy: 0.9818 - val_loss: 0.9377 - val_categorical_accuracy: 0.8837\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0487 - categorical_accuracy: 0.9849 - val_loss: 1.2142 - val_categorical_accuracy: 0.8144\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0543 - categorical_accuracy: 0.9840 - val_loss: 1.1669 - val_categorical_accuracy: 0.8116\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0531 - categorical_accuracy: 0.9830 - val_loss: 0.8426 - val_categorical_accuracy: 0.8975\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0465 - categorical_accuracy: 0.9824 - val_loss: 0.9249 - val_categorical_accuracy: 0.8449\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0472 - categorical_accuracy: 0.9827 - val_loss: 0.9830 - val_categorical_accuracy: 0.8670\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0463 - categorical_accuracy: 0.9864 - val_loss: 1.0443 - val_categorical_accuracy: 0.8366\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0396 - categorical_accuracy: 0.9855 - val_loss: 0.9960 - val_categorical_accuracy: 0.8864\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 428us/step - loss: 0.0407 - categorical_accuracy: 0.9867 - val_loss: 0.8718 - val_categorical_accuracy: 0.8920\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0356 - categorical_accuracy: 0.9864 - val_loss: 0.8889 - val_categorical_accuracy: 0.8698\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0373 - categorical_accuracy: 0.9870 - val_loss: 0.9094 - val_categorical_accuracy: 0.8975\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0367 - categorical_accuracy: 0.9858 - val_loss: 0.4318 - val_categorical_accuracy: 0.9446\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 575us/step - loss: 0.6338 - categorical_accuracy: 0.6287 - val_loss: 0.4979 - val_categorical_accuracy: 0.8476\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.4869 - categorical_accuracy: 0.8466 - val_loss: 0.5783 - val_categorical_accuracy: 0.6704\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.3426 - categorical_accuracy: 0.9037 - val_loss: 0.3271 - val_categorical_accuracy: 0.8587\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.2477 - categorical_accuracy: 0.9364 - val_loss: 0.3381 - val_categorical_accuracy: 0.8504\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.1952 - categorical_accuracy: 0.9478 - val_loss: 0.4384 - val_categorical_accuracy: 0.8144\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.1562 - categorical_accuracy: 0.9537 - val_loss: 0.4456 - val_categorical_accuracy: 0.8227\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.1351 - categorical_accuracy: 0.9593 - val_loss: 0.5869 - val_categorical_accuracy: 0.7839\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.1184 - categorical_accuracy: 0.9617 - val_loss: 0.4093 - val_categorical_accuracy: 0.8726\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.1097 - categorical_accuracy: 0.9676 - val_loss: 0.6365 - val_categorical_accuracy: 0.8199\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0973 - categorical_accuracy: 0.9694 - val_loss: 0.6823 - val_categorical_accuracy: 0.8338\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0870 - categorical_accuracy: 0.9719 - val_loss: 0.6282 - val_categorical_accuracy: 0.8366\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0787 - categorical_accuracy: 0.9784 - val_loss: 0.5224 - val_categorical_accuracy: 0.8476\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0710 - categorical_accuracy: 0.9769 - val_loss: 0.3337 - val_categorical_accuracy: 0.9224\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0714 - categorical_accuracy: 0.9806 - val_loss: 0.4465 - val_categorical_accuracy: 0.9030\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0656 - categorical_accuracy: 0.9802 - val_loss: 0.7995 - val_categorical_accuracy: 0.8255\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0568 - categorical_accuracy: 0.9821 - val_loss: 0.9277 - val_categorical_accuracy: 0.8421\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0569 - categorical_accuracy: 0.9815 - val_loss: 0.7821 - val_categorical_accuracy: 0.8421\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0529 - categorical_accuracy: 0.9821 - val_loss: 0.3991 - val_categorical_accuracy: 0.9197\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0496 - categorical_accuracy: 0.9849 - val_loss: 0.5139 - val_categorical_accuracy: 0.9003\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0515 - categorical_accuracy: 0.9836 - val_loss: 0.5989 - val_categorical_accuracy: 0.9003\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0517 - categorical_accuracy: 0.9833 - val_loss: 0.6864 - val_categorical_accuracy: 0.8837\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0416 - categorical_accuracy: 0.9861 - val_loss: 0.8917 - val_categorical_accuracy: 0.8144\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.0424 - categorical_accuracy: 0.98 - 1s 432us/step - loss: 0.0421 - categorical_accuracy: 0.9855 - val_loss: 0.5767 - val_categorical_accuracy: 0.8920\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0409 - categorical_accuracy: 0.9861 - val_loss: 0.7198 - val_categorical_accuracy: 0.8670\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0393 - categorical_accuracy: 0.9858 - val_loss: 0.5689 - val_categorical_accuracy: 0.9058\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0410 - categorical_accuracy: 0.9889 - val_loss: 0.5409 - val_categorical_accuracy: 0.9030\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0348 - categorical_accuracy: 0.9892 - val_loss: 0.7835 - val_categorical_accuracy: 0.8643\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0374 - categorical_accuracy: 0.9877 - val_loss: 0.6576 - val_categorical_accuracy: 0.8920\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 427us/step - loss: 0.0327 - categorical_accuracy: 0.9892 - val_loss: 0.4071 - val_categorical_accuracy: 0.9335\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0346 - categorical_accuracy: 0.9883 - val_loss: 0.5989 - val_categorical_accuracy: 0.8947\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 583us/step - loss: 0.6481 - categorical_accuracy: 0.6318 - val_loss: 0.6955 - val_categorical_accuracy: 0.4571\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.4903 - categorical_accuracy: 0.8701 - val_loss: 0.6682 - val_categorical_accuracy: 0.5928\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.3199 - categorical_accuracy: 0.9151 - val_loss: 0.4615 - val_categorical_accuracy: 0.7978\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.2242 - categorical_accuracy: 0.9389 - val_loss: 0.8958 - val_categorical_accuracy: 0.6537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.1784 - categorical_accuracy: 0.9460 - val_loss: 0.4581 - val_categorical_accuracy: 0.8421\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.1455 - categorical_accuracy: 0.9565 - val_loss: 0.4868 - val_categorical_accuracy: 0.8421\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.1272 - categorical_accuracy: 0.9590 - val_loss: 0.9623 - val_categorical_accuracy: 0.6981\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.1085 - categorical_accuracy: 0.9633 - val_loss: 0.5584 - val_categorical_accuracy: 0.8421\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0977 - categorical_accuracy: 0.9682 - val_loss: 0.6313 - val_categorical_accuracy: 0.8338\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0879 - categorical_accuracy: 0.9682 - val_loss: 0.8153 - val_categorical_accuracy: 0.7978\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0816 - categorical_accuracy: 0.9728 - val_loss: 0.6320 - val_categorical_accuracy: 0.8421\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0751 - categorical_accuracy: 0.9713 - val_loss: 0.6735 - val_categorical_accuracy: 0.8449\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0710 - categorical_accuracy: 0.9750 - val_loss: 0.4814 - val_categorical_accuracy: 0.9003\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 428us/step - loss: 0.0644 - categorical_accuracy: 0.9762 - val_loss: 0.4764 - val_categorical_accuracy: 0.9086\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0605 - categorical_accuracy: 0.9799 - val_loss: 0.9847 - val_categorical_accuracy: 0.7922\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0598 - categorical_accuracy: 0.9815 - val_loss: 0.6084 - val_categorical_accuracy: 0.8698\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0560 - categorical_accuracy: 0.9793 - val_loss: 0.8616 - val_categorical_accuracy: 0.8393\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0538 - categorical_accuracy: 0.9799 - val_loss: 0.7149 - val_categorical_accuracy: 0.8809\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0506 - categorical_accuracy: 0.9827 - val_loss: 0.5162 - val_categorical_accuracy: 0.9058\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0547 - categorical_accuracy: 0.9818 - val_loss: 0.4996 - val_categorical_accuracy: 0.9224\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0458 - categorical_accuracy: 0.9818 - val_loss: 0.5352 - val_categorical_accuracy: 0.9003\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 428us/step - loss: 0.0444 - categorical_accuracy: 0.9840 - val_loss: 0.7251 - val_categorical_accuracy: 0.8726\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 428us/step - loss: 0.0465 - categorical_accuracy: 0.9833 - val_loss: 0.4486 - val_categorical_accuracy: 0.9197\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0438 - categorical_accuracy: 0.9840 - val_loss: 0.5433 - val_categorical_accuracy: 0.9086\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0412 - categorical_accuracy: 0.9870 - val_loss: 0.5329 - val_categorical_accuracy: 0.9141\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0433 - categorical_accuracy: 0.9836 - val_loss: 0.6846 - val_categorical_accuracy: 0.8726\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0415 - categorical_accuracy: 0.9864 - val_loss: 0.8526 - val_categorical_accuracy: 0.8560\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.0436 - categorical_accuracy: 0.9861 - val_loss: 0.4678 - val_categorical_accuracy: 0.9086\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 429us/step - loss: 0.0363 - categorical_accuracy: 0.9892 - val_loss: 0.7320 - val_categorical_accuracy: 0.8753\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 430us/step - loss: 0.0359 - categorical_accuracy: 0.9849 - val_loss: 0.8620 - val_categorical_accuracy: 0.8560\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 587us/step - loss: 0.6680 - categorical_accuracy: 0.5870 - val_loss: 0.6858 - val_categorical_accuracy: 0.5956\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.5523 - categorical_accuracy: 0.8500 - val_loss: 0.8404 - val_categorical_accuracy: 0.4155\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.3925 - categorical_accuracy: 0.9022 - val_loss: 0.9179 - val_categorical_accuracy: 0.5734\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.2769 - categorical_accuracy: 0.9306 - val_loss: 0.4356 - val_categorical_accuracy: 0.8227\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.2117 - categorical_accuracy: 0.9407 - val_loss: 0.9348 - val_categorical_accuracy: 0.7036\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 432us/step - loss: 0.1709 - categorical_accuracy: 0.9472 - val_loss: 0.9016 - val_categorical_accuracy: 0.7368\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.1449 - categorical_accuracy: 0.95 - 1s 433us/step - loss: 0.1450 - categorical_accuracy: 0.9543 - val_loss: 0.5525 - val_categorical_accuracy: 0.8615\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.1251 - categorical_accuracy: 0.9596 - val_loss: 0.7596 - val_categorical_accuracy: 0.8393\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.1084 - categorical_accuracy: 0.9651 - val_loss: 1.0060 - val_categorical_accuracy: 0.8116\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0969 - categorical_accuracy: 0.9664 - val_loss: 1.1245 - val_categorical_accuracy: 0.8033\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0894 - categorical_accuracy: 0.9701 - val_loss: 1.0278 - val_categorical_accuracy: 0.8199\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0794 - categorical_accuracy: 0.9744 - val_loss: 1.0078 - val_categorical_accuracy: 0.8310\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0717 - categorical_accuracy: 0.9759 - val_loss: 0.8290 - val_categorical_accuracy: 0.8892\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0704 - categorical_accuracy: 0.9759 - val_loss: 1.1627 - val_categorical_accuracy: 0.8366\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0672 - categorical_accuracy: 0.9778 - val_loss: 1.0290 - val_categorical_accuracy: 0.8670\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0618 - categorical_accuracy: 0.9784 - val_loss: 0.8755 - val_categorical_accuracy: 0.8837\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0610 - categorical_accuracy: 0.9793 - val_loss: 0.9704 - val_categorical_accuracy: 0.8698\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0563 - categorical_accuracy: 0.9778 - val_loss: 0.9293 - val_categorical_accuracy: 0.8892\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0556 - categorical_accuracy: 0.9781 - val_loss: 0.8738 - val_categorical_accuracy: 0.8947\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0528 - categorical_accuracy: 0.9818 - val_loss: 0.8198 - val_categorical_accuracy: 0.9058\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0509 - categorical_accuracy: 0.9818 - val_loss: 0.7411 - val_categorical_accuracy: 0.9169\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0482 - categorical_accuracy: 0.9821 - val_loss: 1.0656 - val_categorical_accuracy: 0.8753\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0468 - categorical_accuracy: 0.9824 - val_loss: 1.2992 - val_categorical_accuracy: 0.8560\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0486 - categorical_accuracy: 0.9821 - val_loss: 0.9755 - val_categorical_accuracy: 0.9114\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0437 - categorical_accuracy: 0.9833 - val_loss: 0.8748 - val_categorical_accuracy: 0.9252\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0457 - categorical_accuracy: 0.9830 - val_loss: 0.9512 - val_categorical_accuracy: 0.9030\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0407 - categorical_accuracy: 0.9846 - val_loss: 1.1508 - val_categorical_accuracy: 0.8726\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0391 - categorical_accuracy: 0.9861 - val_loss: 0.8258 - val_categorical_accuracy: 0.9169\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0392 - categorical_accuracy: 0.9855 - val_loss: 0.8466 - val_categorical_accuracy: 0.9058\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0376 - categorical_accuracy: 0.9846 - val_loss: 1.2535 - val_categorical_accuracy: 0.8255\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 608us/step - loss: 0.6511 - categorical_accuracy: 0.5728 - val_loss: 0.6224 - val_categorical_accuracy: 0.7341\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.5197 - categorical_accuracy: 0.8204 - val_loss: 0.5907 - val_categorical_accuracy: 0.7341\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.3630 - categorical_accuracy: 0.9105 - val_loss: 0.5188 - val_categorical_accuracy: 0.7645\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.2498 - categorical_accuracy: 0.9377 - val_loss: 0.5733 - val_categorical_accuracy: 0.7507\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.1857 - categorical_accuracy: 0.9481 - val_loss: 0.3451 - val_categorical_accuracy: 0.8476\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.1507 - categorical_accuracy: 0.9556 - val_loss: 0.5682 - val_categorical_accuracy: 0.7895\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.1255 - categorical_accuracy: 0.9605 - val_loss: 0.3973 - val_categorical_accuracy: 0.8698\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.1081 - categorical_accuracy: 0.9651 - val_loss: 0.3770 - val_categorical_accuracy: 0.8753\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0979 - categorical_accuracy: 0.9694 - val_loss: 0.3926 - val_categorical_accuracy: 0.8643\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0894 - categorical_accuracy: 0.9685 - val_loss: 0.6253 - val_categorical_accuracy: 0.7895\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0835 - categorical_accuracy: 0.9728 - val_loss: 0.4386 - val_categorical_accuracy: 0.8504\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0734 - categorical_accuracy: 0.9765 - val_loss: 0.6568 - val_categorical_accuracy: 0.8227\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0715 - categorical_accuracy: 0.9793 - val_loss: 0.4002 - val_categorical_accuracy: 0.9003\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0625 - categorical_accuracy: 0.9809 - val_loss: 0.5239 - val_categorical_accuracy: 0.8615\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0619 - categorical_accuracy: 0.9787 - val_loss: 0.4815 - val_categorical_accuracy: 0.8615\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0648 - categorical_accuracy: 0.9806 - val_loss: 0.4446 - val_categorical_accuracy: 0.8975\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0537 - categorical_accuracy: 0.9821 - val_loss: 0.6562 - val_categorical_accuracy: 0.8421\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0533 - categorical_accuracy: 0.9827 - val_loss: 0.6282 - val_categorical_accuracy: 0.8393\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0513 - categorical_accuracy: 0.9824 - val_loss: 0.3899 - val_categorical_accuracy: 0.9114\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0470 - categorical_accuracy: 0.9827 - val_loss: 0.5796 - val_categorical_accuracy: 0.8615\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0476 - categorical_accuracy: 0.9846 - val_loss: 0.5797 - val_categorical_accuracy: 0.8476\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0449 - categorical_accuracy: 0.9843 - val_loss: 0.5253 - val_categorical_accuracy: 0.8837\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0461 - categorical_accuracy: 0.9846 - val_loss: 0.4443 - val_categorical_accuracy: 0.8947\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0430 - categorical_accuracy: 0.9840 - val_loss: 0.4482 - val_categorical_accuracy: 0.8864\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0451 - categorical_accuracy: 0.9830 - val_loss: 0.2740 - val_categorical_accuracy: 0.9418\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0414 - categorical_accuracy: 0.9867 - val_loss: 0.7121 - val_categorical_accuracy: 0.8504\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0410 - categorical_accuracy: 0.9840 - val_loss: 0.6719 - val_categorical_accuracy: 0.8615\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0365 - categorical_accuracy: 0.9892 - val_loss: 0.6197 - val_categorical_accuracy: 0.8698\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0368 - categorical_accuracy: 0.9864 - val_loss: 0.5787 - val_categorical_accuracy: 0.8809\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0375 - categorical_accuracy: 0.9898 - val_loss: 0.8999 - val_categorical_accuracy: 0.8144\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 594us/step - loss: 0.6263 - categorical_accuracy: 0.6935 - val_loss: 0.6267 - val_categorical_accuracy: 0.7230\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.4298 - categorical_accuracy: 0.8620 - val_loss: 0.7269 - val_categorical_accuracy: 0.6094\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.2864 - categorical_accuracy: 0.9160 - val_loss: 0.4408 - val_categorical_accuracy: 0.8310\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.2056 - categorical_accuracy: 0.9398 - val_loss: 1.1016 - val_categorical_accuracy: 0.6399\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.1633 - categorical_accuracy: 0.9466 - val_loss: 0.5950 - val_categorical_accuracy: 0.8449\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.1365 - categorical_accuracy: 0.9617 - val_loss: 0.5101 - val_categorical_accuracy: 0.8698\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.1163 - categorical_accuracy: 0.9627 - val_loss: 0.7234 - val_categorical_accuracy: 0.8255\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.1012 - categorical_accuracy: 0.9660 - val_loss: 0.8883 - val_categorical_accuracy: 0.8172\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 1s 450us/step - loss: 0.0914 - categorical_accuracy: 0.9682 - val_loss: 0.7846 - val_categorical_accuracy: 0.8476\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 451us/step - loss: 0.0830 - categorical_accuracy: 0.9722 - val_loss: 0.8462 - val_categorical_accuracy: 0.8449\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.0767 - categorical_accuracy: 0.97 - 1s 444us/step - loss: 0.0766 - categorical_accuracy: 0.9735 - val_loss: 1.3536 - val_categorical_accuracy: 0.7673\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 444us/step - loss: 0.0720 - categorical_accuracy: 0.9762 - val_loss: 0.7435 - val_categorical_accuracy: 0.8753\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 449us/step - loss: 0.0645 - categorical_accuracy: 0.9787 - val_loss: 1.0105 - val_categorical_accuracy: 0.8393\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0604 - categorical_accuracy: 0.9836 - val_loss: 0.9621 - val_categorical_accuracy: 0.8560\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0595 - categorical_accuracy: 0.9790 - val_loss: 0.9687 - val_categorical_accuracy: 0.8338\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0609 - categorical_accuracy: 0.9821 - val_loss: 0.9585 - val_categorical_accuracy: 0.8670\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0536 - categorical_accuracy: 0.9821 - val_loss: 0.5099 - val_categorical_accuracy: 0.8947\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0510 - categorical_accuracy: 0.9821 - val_loss: 0.7536 - val_categorical_accuracy: 0.8920\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0495 - categorical_accuracy: 0.9827 - val_loss: 0.4827 - val_categorical_accuracy: 0.9197\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 431us/step - loss: 0.0489 - categorical_accuracy: 0.9849 - val_loss: 0.7807 - val_categorical_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 452us/step - loss: 0.0455 - categorical_accuracy: 0.9846 - val_loss: 0.6735 - val_categorical_accuracy: 0.8864\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 449us/step - loss: 0.0466 - categorical_accuracy: 0.9846 - val_loss: 0.7456 - val_categorical_accuracy: 0.8809\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0457 - categorical_accuracy: 0.9852 - val_loss: 0.7808 - val_categorical_accuracy: 0.8560\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0434 - categorical_accuracy: 0.9877 - val_loss: 0.5203 - val_categorical_accuracy: 0.8892\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0423 - categorical_accuracy: 0.9852 - val_loss: 0.4004 - val_categorical_accuracy: 0.9335\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.0422 - categorical_accuracy: 0.9855 - val_loss: 0.7672 - val_categorical_accuracy: 0.8837\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0376 - categorical_accuracy: 0.9867 - val_loss: 0.6374 - val_categorical_accuracy: 0.8864\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0384 - categorical_accuracy: 0.9855 - val_loss: 0.6903 - val_categorical_accuracy: 0.8920\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0398 - categorical_accuracy: 0.9873 - val_loss: 0.5397 - val_categorical_accuracy: 0.8920\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0388 - categorical_accuracy: 0.9873 - val_loss: 0.2808 - val_categorical_accuracy: 0.9418\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 619us/step - loss: 0.6437 - categorical_accuracy: 0.6497 - val_loss: 0.5336 - val_categorical_accuracy: 0.8947\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 444us/step - loss: 0.4688 - categorical_accuracy: 0.8608 - val_loss: 0.6193 - val_categorical_accuracy: 0.7091\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.3084 - categorical_accuracy: 0.9182 - val_loss: 0.6474 - val_categorical_accuracy: 0.7673\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.2192 - categorical_accuracy: 0.9389 - val_loss: 0.5957 - val_categorical_accuracy: 0.7729\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.1732 - categorical_accuracy: 0.9472 - val_loss: 0.4582 - val_categorical_accuracy: 0.8615\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.1434 - categorical_accuracy: 0.9552 - val_loss: 0.7508 - val_categorical_accuracy: 0.7562\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.1229 - categorical_accuracy: 0.9608 - val_loss: 0.4368 - val_categorical_accuracy: 0.8809\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.1064 - categorical_accuracy: 0.9648 - val_loss: 0.7639 - val_categorical_accuracy: 0.7839\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0972 - categorical_accuracy: 0.9679 - val_loss: 0.7241 - val_categorical_accuracy: 0.8033\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0863 - categorical_accuracy: 0.9716 - val_loss: 0.5363 - val_categorical_accuracy: 0.8560\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0808 - categorical_accuracy: 0.9731 - val_loss: 0.5129 - val_categorical_accuracy: 0.8726\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0746 - categorical_accuracy: 0.9744 - val_loss: 0.4978 - val_categorical_accuracy: 0.8975\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 434us/step - loss: 0.0685 - categorical_accuracy: 0.9793 - val_loss: 0.4180 - val_categorical_accuracy: 0.9252\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0644 - categorical_accuracy: 0.9744 - val_loss: 0.5299 - val_categorical_accuracy: 0.8975\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0615 - categorical_accuracy: 0.9809 - val_loss: 0.5809 - val_categorical_accuracy: 0.8670\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0595 - categorical_accuracy: 0.9787 - val_loss: 0.3745 - val_categorical_accuracy: 0.9169\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0560 - categorical_accuracy: 0.9821 - val_loss: 0.5917 - val_categorical_accuracy: 0.8698\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0561 - categorical_accuracy: 0.9833 - val_loss: 0.5718 - val_categorical_accuracy: 0.8975\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0533 - categorical_accuracy: 0.9821 - val_loss: 0.5372 - val_categorical_accuracy: 0.8920\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 435us/step - loss: 0.0510 - categorical_accuracy: 0.9818 - val_loss: 0.4521 - val_categorical_accuracy: 0.9114\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 436us/step - loss: 0.0463 - categorical_accuracy: 0.9852 - val_loss: 0.5770 - val_categorical_accuracy: 0.8809\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 433us/step - loss: 0.0459 - categorical_accuracy: 0.9824 - val_loss: 0.7226 - val_categorical_accuracy: 0.8421\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0450 - categorical_accuracy: 0.9855 - val_loss: 0.5422 - val_categorical_accuracy: 0.8975\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.0446 - categorical_accuracy: 0.9852 - val_loss: 0.9978 - val_categorical_accuracy: 0.8338\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.0428 - categorical_accuracy: 0.9858 - val_loss: 0.8378 - val_categorical_accuracy: 0.8615\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0435 - categorical_accuracy: 0.9870 - val_loss: 0.4088 - val_categorical_accuracy: 0.9252\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.0381 - categorical_accuracy: 0.9877 - val_loss: 0.3987 - val_categorical_accuracy: 0.9280\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0384 - categorical_accuracy: 0.9855 - val_loss: 0.3496 - val_categorical_accuracy: 0.9280\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0366 - categorical_accuracy: 0.9867 - val_loss: 0.3551 - val_categorical_accuracy: 0.9169\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0363 - categorical_accuracy: 0.9877 - val_loss: 0.4083 - val_categorical_accuracy: 0.9030\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 635us/step - loss: 0.6641 - categorical_accuracy: 0.5407 - val_loss: 0.6387 - val_categorical_accuracy: 0.8809\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 450us/step - loss: 0.5566 - categorical_accuracy: 0.8052 - val_loss: 0.7410 - val_categorical_accuracy: 0.6759\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.3987 - categorical_accuracy: 0.9108 - val_loss: 0.6600 - val_categorical_accuracy: 0.6731\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.2805 - categorical_accuracy: 0.9309 - val_loss: 0.7103 - val_categorical_accuracy: 0.6953\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 446us/step - loss: 0.2114 - categorical_accuracy: 0.9454 - val_loss: 0.2743 - val_categorical_accuracy: 0.8643\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.1765 - categorical_accuracy: 0.9512 - val_loss: 0.4185 - val_categorical_accuracy: 0.8255\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.1514 - categorical_accuracy: 0.9580 - val_loss: 0.5454 - val_categorical_accuracy: 0.8061\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 456us/step - loss: 0.1302 - categorical_accuracy: 0.9602 - val_loss: 0.6178 - val_categorical_accuracy: 0.8061\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 458us/step - loss: 0.1177 - categorical_accuracy: 0.9633 - val_loss: 0.7059 - val_categorical_accuracy: 0.8144\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.1040 - categorical_accuracy: 0.9688 - val_loss: 0.8025 - val_categorical_accuracy: 0.8061\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 454us/step - loss: 0.0953 - categorical_accuracy: 0.9704 - val_loss: 0.6665 - val_categorical_accuracy: 0.8615\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.0875 - categorical_accuracy: 0.9725 - val_loss: 0.8261 - val_categorical_accuracy: 0.8144\n",
      "Epoch 13/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.0802 - categorical_accuracy: 0.9722 - val_loss: 0.7530 - val_categorical_accuracy: 0.8670\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.0769 - categorical_accuracy: 0.9756 - val_loss: 0.8280 - val_categorical_accuracy: 0.8421\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 450us/step - loss: 0.0713 - categorical_accuracy: 0.9778 - val_loss: 0.5872 - val_categorical_accuracy: 0.8753\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 449us/step - loss: 0.0693 - categorical_accuracy: 0.9769 - val_loss: 0.6079 - val_categorical_accuracy: 0.8920\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 460us/step - loss: 0.0631 - categorical_accuracy: 0.9778 - val_loss: 1.1210 - val_categorical_accuracy: 0.8144\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 462us/step - loss: 0.0629 - categorical_accuracy: 0.9784 - val_loss: 1.1083 - val_categorical_accuracy: 0.8089\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - 2s 481us/step - loss: 0.0571 - categorical_accuracy: 0.9802 - val_loss: 1.0495 - val_categorical_accuracy: 0.8393\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 2s 467us/step - loss: 0.0579 - categorical_accuracy: 0.9802 - val_loss: 1.3770 - val_categorical_accuracy: 0.7895\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 449us/step - loss: 0.0563 - categorical_accuracy: 0.9787 - val_loss: 1.1834 - val_categorical_accuracy: 0.8310\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.0524 - categorical_accuracy: 0.9815 - val_loss: 0.8982 - val_categorical_accuracy: 0.8560\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.0517 - categorical_accuracy: 0.9833 - val_loss: 1.0409 - val_categorical_accuracy: 0.8504\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.0538 - categorical_accuracy: 0.9812 - val_loss: 1.3700 - val_categorical_accuracy: 0.8089\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.0497 - categorical_accuracy: 0.9802 - val_loss: 1.0612 - val_categorical_accuracy: 0.8532\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.0478 - categorical_accuracy: 0.9830 - val_loss: 0.9601 - val_categorical_accuracy: 0.8726\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.0471 - categorical_accuracy: 0.9846 - val_loss: 0.9736 - val_categorical_accuracy: 0.8532\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.0430 - categorical_accuracy: 0.9840 - val_loss: 0.9623 - val_categorical_accuracy: 0.8532\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 450us/step - loss: 0.0467 - categorical_accuracy: 0.9855 - val_loss: 1.1873 - val_categorical_accuracy: 0.8255\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 444us/step - loss: 0.0433 - categorical_accuracy: 0.9846 - val_loss: 0.9459 - val_categorical_accuracy: 0.8753\n",
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/30\n",
      "3240/3240 [==============================] - 2s 627us/step - loss: 0.6274 - categorical_accuracy: 0.6241 - val_loss: 0.9863 - val_categorical_accuracy: 0.3213\n",
      "Epoch 2/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.4559 - categorical_accuracy: 0.8688 - val_loss: 1.1371 - val_categorical_accuracy: 0.5069\n",
      "Epoch 3/30\n",
      "3240/3240 [==============================] - 1s 446us/step - loss: 0.3040 - categorical_accuracy: 0.9228 - val_loss: 0.8335 - val_categorical_accuracy: 0.7590\n",
      "Epoch 4/30\n",
      "3240/3240 [==============================] - 1s 446us/step - loss: 0.2176 - categorical_accuracy: 0.9423 - val_loss: 0.3010 - val_categorical_accuracy: 0.9058\n",
      "Epoch 5/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.1917 - categorical_accuracy: 0.9540 - val_loss: 0.2804 - val_categorical_accuracy: 0.9252\n",
      "Epoch 6/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.1504 - categorical_accuracy: 0.9546 - val_loss: 1.0688 - val_categorical_accuracy: 0.7922\n",
      "Epoch 7/30\n",
      "3240/3240 [==============================] - 1s 450us/step - loss: 0.1321 - categorical_accuracy: 0.9593 - val_loss: 0.9115 - val_categorical_accuracy: 0.8006\n",
      "Epoch 8/30\n",
      "3240/3240 [==============================] - 1s 449us/step - loss: 0.1178 - categorical_accuracy: 0.9645 - val_loss: 0.7165 - val_categorical_accuracy: 0.8643\n",
      "Epoch 9/30\n",
      "3240/3240 [==============================] - 1s 448us/step - loss: 0.1024 - categorical_accuracy: 0.9685 - val_loss: 0.4826 - val_categorical_accuracy: 0.8892\n",
      "Epoch 10/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.0970 - categorical_accuracy: 0.9713 - val_loss: 0.9412 - val_categorical_accuracy: 0.8283\n",
      "Epoch 11/30\n",
      "3240/3240 [==============================] - 1s 447us/step - loss: 0.0928 - categorical_accuracy: 0.9728 - val_loss: 0.5986 - val_categorical_accuracy: 0.8781\n",
      "Epoch 12/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.0834 - categorical_accuracy: 0.9753 - val_loss: 0.8567 - val_categorical_accuracy: 0.8670\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0730 - categorical_accuracy: 0.9756 - val_loss: 0.3445 - val_categorical_accuracy: 0.9280\n",
      "Epoch 14/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0714 - categorical_accuracy: 0.9775 - val_loss: 0.7585 - val_categorical_accuracy: 0.8670\n",
      "Epoch 15/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.0695 - categorical_accuracy: 0.9772 - val_loss: 0.6529 - val_categorical_accuracy: 0.8809\n",
      "Epoch 16/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0677 - categorical_accuracy: 0.9787 - val_loss: 0.8212 - val_categorical_accuracy: 0.8753\n",
      "Epoch 17/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0567 - categorical_accuracy: 0.9809 - val_loss: 0.5652 - val_categorical_accuracy: 0.9030\n",
      "Epoch 18/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0593 - categorical_accuracy: 0.9793 - val_loss: 0.7207 - val_categorical_accuracy: 0.8532\n",
      "Epoch 19/30\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 0.0567 - categorical_accuracy: 0.98 - 1s 442us/step - loss: 0.0564 - categorical_accuracy: 0.9802 - val_loss: 0.9070 - val_categorical_accuracy: 0.8476\n",
      "Epoch 20/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0498 - categorical_accuracy: 0.9858 - val_loss: 0.2110 - val_categorical_accuracy: 0.9584\n",
      "Epoch 21/30\n",
      "3240/3240 [==============================] - 1s 443us/step - loss: 0.0541 - categorical_accuracy: 0.9836 - val_loss: 0.5209 - val_categorical_accuracy: 0.9030\n",
      "Epoch 22/30\n",
      "3240/3240 [==============================] - 1s 441us/step - loss: 0.0466 - categorical_accuracy: 0.9843 - val_loss: 1.1929 - val_categorical_accuracy: 0.8089\n",
      "Epoch 23/30\n",
      "3240/3240 [==============================] - 1s 437us/step - loss: 0.0562 - categorical_accuracy: 0.9849 - val_loss: 0.6418 - val_categorical_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0531 - categorical_accuracy: 0.9836 - val_loss: 0.7244 - val_categorical_accuracy: 0.9058\n",
      "Epoch 25/30\n",
      "3240/3240 [==============================] - 1s 439us/step - loss: 0.0422 - categorical_accuracy: 0.9858 - val_loss: 0.7037 - val_categorical_accuracy: 0.9003\n",
      "Epoch 26/30\n",
      "3240/3240 [==============================] - 1s 440us/step - loss: 0.0480 - categorical_accuracy: 0.9840 - val_loss: 0.6934 - val_categorical_accuracy: 0.9058\n",
      "Epoch 27/30\n",
      "3240/3240 [==============================] - 1s 442us/step - loss: 0.0439 - categorical_accuracy: 0.9864 - val_loss: 0.9323 - val_categorical_accuracy: 0.8837\n",
      "Epoch 28/30\n",
      "3240/3240 [==============================] - 1s 444us/step - loss: 0.0410 - categorical_accuracy: 0.9846 - val_loss: 0.7953 - val_categorical_accuracy: 0.9252\n",
      "Epoch 29/30\n",
      "3240/3240 [==============================] - 1s 438us/step - loss: 0.0383 - categorical_accuracy: 0.9883 - val_loss: 0.5401 - val_categorical_accuracy: 0.9030\n",
      "Epoch 30/30\n",
      "3240/3240 [==============================] - 1s 445us/step - loss: 0.0406 - categorical_accuracy: 0.9870 - val_loss: 0.3887 - val_categorical_accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.9750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.9750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.9750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  0.9551\n",
       "1  0.9750\n",
       "2  0.9750\n",
       "3  0.9725\n",
       "4  0.9550\n",
       "5  0.9650\n",
       "6  0.9800\n",
       "7  0.9800\n",
       "8  0.9750\n",
       "9  0.9675"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# Let's train the model using RMSprop\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "acc_row = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    #x_train /= 255\n",
    "    #x_test /= 255\n",
    "    print(y_train)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.1)\n",
    "\n",
    "    loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "    acc_row.append(acc)\n",
    "res = pd.DataFrame(acc_row)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 307us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2648034638013576, 0.9725343585014343]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
