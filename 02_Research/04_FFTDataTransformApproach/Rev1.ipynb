{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_learn_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainwave Frequencies:\n",
    "Gamma, 30 to 50 Hz.  \n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n",
    "Delta, 0.1 to 4 Hz.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Bin Size: \n",
    "https://stackoverflow.com/questions/25735153/plotting-a-fast-fourier-transform-in-python  \n",
    "(Search for 'bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An EEG processing library:  \n",
    "https://github.com/pbashivan/EEGLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds \n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = 100#Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = 100#Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "            \n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "    \n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = 100#Fs * frame_duration\n",
    "    \n",
    "    print('Generating training data...')\n",
    "    \n",
    "    \n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',')\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "        \n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3) \n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "        \n",
    "    X_r = X[:,:,:,0].reshape((X.shape[0]*image_size, image_size))\n",
    "    X_g = X[:,:,:,1].reshape((X.shape[0]*image_size, image_size))\n",
    "    X_b = X[:,:,:,2].reshape((X.shape[0]*image_size, image_size))\n",
    "    \n",
    "    X[:,:,:,0] = scale(X_r, axis = 1).reshape((X.shape[0], X.shape[1], X.shape[2])) \n",
    "    X[:,:,:,1] = scale(X_g, axis = 1).reshape((X.shape[0], X.shape[1], X.shape[2])) \n",
    "    X[:,:,:,2] = scale(X_b, axis = 1).reshape((X.shape[0], X.shape[1], X.shape[2]))     \n",
    "    return X,np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/data_train_new_appr_1_label1.csv . ( 1  of  4 )\n",
      "Interpolating 796/796nterpolating 22/796Interpolating 42/796Interpolating 63/796Interpolating 85/796Interpolating 105/796Interpolating 126/796Interpolating 148/796Interpolating 168/796Interpolating 187/796Interpolating 207/796Interpolating 225/796Interpolating 244/796Interpolating 265/796Interpolating 286/796Interpolating 306/796Interpolating 328/796Interpolating 348/796Interpolating 369/796Interpolating 390/796Interpolating 411/796Interpolating 433/796Interpolating 453/796Interpolating 473/796Interpolating 490/796Interpolating 509/796Interpolating 528/796Interpolating 569/796Interpolating 589/796Interpolating 606/796Interpolating 623/796Interpolating 642/796Interpolating 682/796Interpolating 702/796Interpolating 723/796Interpolating 742/796Interpolating 763/796796  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/data_train_new_appr_2_label0.csv . ( 2  of  4 )\n",
      "796  frames generated with label  0 .796Interpolating 39/796Interpolating 80/796Interpolating 101/796Interpolating 122/796Interpolating 162/796Interpolating 183/796Interpolating 204/796Interpolating 225/796Interpolating 242/796Interpolating 260/796Interpolating 280/796Interpolating 301/796Interpolating 322/796Interpolating 343/796Interpolating 364/796Interpolating 385/796Interpolating 405/796Interpolating 425/796Interpolating 446/796Interpolating 467/796Interpolating 487/796Interpolating 507/796Interpolating 527/796Interpolating 566/796Interpolating 587/796Interpolating 608/796Interpolating 629/796Interpolating 650/796Interpolating 670/796Interpolating 690/796Interpolating 711/796Interpolating 732/796Interpolating 753/796Interpolating 773/796Interpolating 795/796\n",
      "\n",
      "\n",
      "Processing session:  data/data_train_new_appr_3_label1.csv . ( 3  of  4 )\n",
      "Interpolating 796/796nterpolating 21/796Interpolating 41/796Interpolating 63/796Interpolating 83/796Interpolating 102/796Interpolating 123/796Interpolating 144/796Interpolating 165/796Interpolating 185/796Interpolating 205/796Interpolating 226/796Interpolating 265/796Interpolating 286/796Interpolating 306/796Interpolating 325/796Interpolating 344/796Interpolating 363/796Interpolating 383/796Interpolating 404/796Interpolating 424/796Interpolating 444/796Interpolating 465/796Interpolating 484/796Interpolating 505/796Interpolating 526/796Interpolating 546/796Interpolating 565/796Interpolating 586/796Interpolating 606/796Interpolating 627/796Interpolating 648/796Interpolating 668/796Interpolating 705/796Interpolating 725/796Interpolating 765/796Interpolating 786/796796  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/data_train_new_appr_4_label0.csv . ( 4  of  4 )\n",
      "Interpolating 796/796nterpolating 22/796Interpolating 42/796Interpolating 62/796Interpolating 82/796Interpolating 103/796Interpolating 124/796Interpolating 144/796Interpolating 164/796Interpolating 184/796Interpolating 205/796Interpolating 226/796Interpolating 246/796Interpolating 266/796Interpolating 286/796Interpolating 306/796Interpolating 326/796Interpolating 346/796Interpolating 366/796Interpolating 385/796Interpolating 405/796Interpolating 425/796Interpolating 445/796Interpolating 464/796Interpolating 484/796Interpolating 505/796Interpolating 525/796Interpolating 545/796Interpolating 565/796Interpolating 585/796Interpolating 605/796Interpolating 624/796Interpolating 644/796Interpolating 663/796Interpolating 684/796Interpolating 705/796Interpolating 726/796Interpolating 747/796Interpolating 766/796Interpolating 785/796796  frames generated with label  0 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_names = ['data/data_train_new_appr_1_label1.csv',\n",
    "              'data/data_train_new_appr_2_label0.csv',\n",
    "              'data/data_train_new_appr_3_label1.csv',\n",
    "              'data/data_train_new_appr_4_label0.csv']\n",
    "labels = [1,0, 1, 0]\n",
    "image_size = 64\n",
    "frame_duration = 0.78\n",
    "overlap = 0.75\n",
    "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20985581e08>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "zero = np.zeros((64,64,3))\n",
    "zero[:,:,2] = X[3,:,:,2]\n",
    "plt.imshow(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20985768fc8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "zero = np.zeros((64,64,3))\n",
    "zero[:,:,1] = X[3,:,:,1]\n",
    "plt.imshow(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2098582ee88>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "zero = np.zeros((64,64,3))\n",
    "zero[:,:,0] = X[1,:,:,0]\n",
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640,480))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('M','P','4','V')\n",
    "fps = 30\n",
    "video_filename = 'output.avi'\n",
    "out = cv2.VideoWriter(video_filename, fourcc, fps, (64, 64))\n",
    "# fourcc = cv2.cv.CV_FOURCC(*'mp4v')\n",
    "\n",
    "for f in X:\n",
    "    gray = cv2.normalize(f, None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    gray_3c = cv2.merge([gray, gray, gray])\n",
    "    out.write(gray_3c)\n",
    "\n",
    "    out.write(f)\n",
    "out.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2865,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2865, 64, 64, 3)\n",
      "2865 train samples\n",
      "319 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2394 samples, validate on 599 samples\n",
      "Epoch 1/200\n",
      "2394/2394 [==============================] - 4s 2ms/step - loss: 0.6978 - accuracy: 0.5175 - val_loss: 0.6888 - val_accuracy: 0.5710\n",
      "Epoch 2/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6864 - accuracy: 0.5251 - val_loss: 0.6911 - val_accuracy: 0.4925\n",
      "Epoch 3/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6837 - accuracy: 0.5409 - val_loss: 0.6837 - val_accuracy: 0.5342\n",
      "Epoch 4/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6813 - accuracy: 0.5455 - val_loss: 0.6836 - val_accuracy: 0.5376\n",
      "Epoch 5/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6787 - accuracy: 0.5551 - val_loss: 0.6769 - val_accuracy: 0.5843\n",
      "Epoch 6/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6755 - accuracy: 0.5639 - val_loss: 0.6801 - val_accuracy: 0.5492\n",
      "Epoch 7/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6739 - accuracy: 0.5706 - val_loss: 0.6801 - val_accuracy: 0.5476\n",
      "Epoch 8/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6729 - accuracy: 0.5727 - val_loss: 0.6707 - val_accuracy: 0.5977\n",
      "Epoch 9/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6696 - accuracy: 0.5652 - val_loss: 0.6705 - val_accuracy: 0.5960\n",
      "Epoch 10/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6677 - accuracy: 0.5723 - val_loss: 0.6685 - val_accuracy: 0.6060\n",
      "Epoch 11/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6661 - accuracy: 0.5764 - val_loss: 0.6657 - val_accuracy: 0.6244\n",
      "Epoch 12/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6638 - accuracy: 0.5852 - val_loss: 0.6641 - val_accuracy: 0.6160\n",
      "Epoch 13/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6617 - accuracy: 0.5936 - val_loss: 0.6664 - val_accuracy: 0.5826\n",
      "Epoch 14/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6602 - accuracy: 0.5973 - val_loss: 0.6661 - val_accuracy: 0.5860\n",
      "Epoch 15/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6584 - accuracy: 0.5927 - val_loss: 0.6646 - val_accuracy: 0.5860\n",
      "Epoch 16/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6568 - accuracy: 0.5990 - val_loss: 0.6614 - val_accuracy: 0.6194\n",
      "Epoch 17/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6550 - accuracy: 0.6061 - val_loss: 0.6623 - val_accuracy: 0.6027\n",
      "Epoch 18/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6537 - accuracy: 0.6074 - val_loss: 0.6646 - val_accuracy: 0.5977\n",
      "Epoch 19/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6522 - accuracy: 0.5998 - val_loss: 0.6633 - val_accuracy: 0.5910\n",
      "Epoch 20/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6507 - accuracy: 0.5990 - val_loss: 0.6687 - val_accuracy: 0.5609\n",
      "Epoch 21/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6497 - accuracy: 0.6074 - val_loss: 0.6599 - val_accuracy: 0.6160\n",
      "Epoch 22/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6482 - accuracy: 0.6023 - val_loss: 0.6606 - val_accuracy: 0.6077\n",
      "Epoch 23/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6462 - accuracy: 0.6036 - val_loss: 0.6612 - val_accuracy: 0.6177\n",
      "Epoch 24/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6445 - accuracy: 0.6211 - val_loss: 0.6611 - val_accuracy: 0.5843\n",
      "Epoch 25/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6428 - accuracy: 0.6186 - val_loss: 0.6596 - val_accuracy: 0.6027\n",
      "Epoch 26/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6418 - accuracy: 0.6190 - val_loss: 0.6665 - val_accuracy: 0.5676\n",
      "Epoch 27/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6404 - accuracy: 0.6149 - val_loss: 0.6585 - val_accuracy: 0.6010\n",
      "Epoch 28/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6414 - accuracy: 0.6107 - val_loss: 0.6601 - val_accuracy: 0.5910\n",
      "Epoch 29/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6379 - accuracy: 0.6174 - val_loss: 0.6895 - val_accuracy: 0.5543\n",
      "Epoch 30/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6356 - accuracy: 0.6266 - val_loss: 0.6594 - val_accuracy: 0.6010\n",
      "Epoch 31/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6368 - accuracy: 0.6161 - val_loss: 0.6603 - val_accuracy: 0.5843\n",
      "Epoch 32/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6346 - accuracy: 0.6270 - val_loss: 0.6603 - val_accuracy: 0.6043\n",
      "Epoch 33/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6343 - accuracy: 0.6228 - val_loss: 0.6674 - val_accuracy: 0.5643\n",
      "Epoch 34/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6337 - accuracy: 0.6320 - val_loss: 0.6654 - val_accuracy: 0.5843\n",
      "Epoch 35/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6317 - accuracy: 0.6282 - val_loss: 0.6618 - val_accuracy: 0.5893\n",
      "Epoch 36/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6287 - accuracy: 0.6324 - val_loss: 0.6648 - val_accuracy: 0.5593\n",
      "Epoch 37/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6277 - accuracy: 0.6257 - val_loss: 0.6610 - val_accuracy: 0.6060\n",
      "Epoch 38/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6252 - accuracy: 0.6374 - val_loss: 0.6693 - val_accuracy: 0.5659\n",
      "Epoch 39/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6268 - accuracy: 0.6345 - val_loss: 0.6615 - val_accuracy: 0.6010\n",
      "Epoch 40/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6241 - accuracy: 0.6332 - val_loss: 0.6612 - val_accuracy: 0.6110\n",
      "Epoch 41/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6234 - accuracy: 0.6391 - val_loss: 0.6678 - val_accuracy: 0.6077\n",
      "Epoch 42/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6218 - accuracy: 0.6241 - val_loss: 0.6650 - val_accuracy: 0.6127\n",
      "Epoch 43/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6214 - accuracy: 0.6291 - val_loss: 0.6652 - val_accuracy: 0.5710\n",
      "Epoch 44/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6212 - accuracy: 0.6387 - val_loss: 0.6618 - val_accuracy: 0.6010\n",
      "Epoch 45/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6188 - accuracy: 0.6408 - val_loss: 0.6646 - val_accuracy: 0.6077\n",
      "Epoch 46/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6182 - accuracy: 0.6466 - val_loss: 0.6664 - val_accuracy: 0.5910\n",
      "Epoch 47/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6172 - accuracy: 0.6433 - val_loss: 0.6760 - val_accuracy: 0.5743\n",
      "Epoch 48/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6149 - accuracy: 0.6470 - val_loss: 0.6685 - val_accuracy: 0.5793\n",
      "Epoch 49/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6148 - accuracy: 0.6420 - val_loss: 0.6737 - val_accuracy: 0.5676\n",
      "Epoch 50/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6134 - accuracy: 0.6479 - val_loss: 0.6618 - val_accuracy: 0.6093\n",
      "Epoch 51/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6147 - accuracy: 0.6391 - val_loss: 0.6945 - val_accuracy: 0.5593\n",
      "Epoch 52/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6106 - accuracy: 0.6470 - val_loss: 0.6631 - val_accuracy: 0.5993\n",
      "Epoch 53/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6097 - accuracy: 0.6495 - val_loss: 0.6671 - val_accuracy: 0.5993\n",
      "Epoch 54/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6083 - accuracy: 0.6416 - val_loss: 0.6701 - val_accuracy: 0.5993\n",
      "Epoch 55/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6084 - accuracy: 0.6520 - val_loss: 0.6665 - val_accuracy: 0.6027\n",
      "Epoch 56/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.6533 - val_loss: 0.6774 - val_accuracy: 0.5626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6057 - accuracy: 0.6546 - val_loss: 0.6712 - val_accuracy: 0.5810\n",
      "Epoch 58/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6029 - accuracy: 0.6571 - val_loss: 0.6724 - val_accuracy: 0.5977\n",
      "Epoch 59/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6024 - accuracy: 0.6550 - val_loss: 0.6702 - val_accuracy: 0.6060\n",
      "Epoch 60/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6033 - accuracy: 0.6550 - val_loss: 0.6677 - val_accuracy: 0.6043\n",
      "Epoch 61/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6035 - accuracy: 0.6579 - val_loss: 0.6669 - val_accuracy: 0.5943\n",
      "Epoch 62/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6048 - accuracy: 0.6479 - val_loss: 0.6792 - val_accuracy: 0.5726\n",
      "Epoch 63/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.6558 - val_loss: 0.6700 - val_accuracy: 0.6010\n",
      "Epoch 64/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5973 - accuracy: 0.6587 - val_loss: 0.6713 - val_accuracy: 0.5927\n",
      "Epoch 65/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5967 - accuracy: 0.6579 - val_loss: 0.6686 - val_accuracy: 0.6043\n",
      "Epoch 66/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.6566 - val_loss: 0.6921 - val_accuracy: 0.5776\n",
      "Epoch 67/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.6662 - val_loss: 0.6747 - val_accuracy: 0.6110\n",
      "Epoch 68/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5952 - accuracy: 0.6591 - val_loss: 0.6735 - val_accuracy: 0.5960\n",
      "Epoch 69/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.6654 - val_loss: 0.6710 - val_accuracy: 0.6093\n",
      "Epoch 70/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5911 - accuracy: 0.6625 - val_loss: 0.6717 - val_accuracy: 0.6043\n",
      "Epoch 71/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5898 - accuracy: 0.6700 - val_loss: 0.6733 - val_accuracy: 0.5977\n",
      "Epoch 72/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5891 - accuracy: 0.6608 - val_loss: 0.6746 - val_accuracy: 0.6060\n",
      "Epoch 73/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5902 - accuracy: 0.6696 - val_loss: 0.6738 - val_accuracy: 0.5760\n",
      "Epoch 74/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5861 - accuracy: 0.6671 - val_loss: 0.6772 - val_accuracy: 0.6010\n",
      "Epoch 75/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5839 - accuracy: 0.6688 - val_loss: 0.6729 - val_accuracy: 0.5927\n",
      "Epoch 76/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5849 - accuracy: 0.6658 - val_loss: 0.6800 - val_accuracy: 0.6027\n",
      "Epoch 77/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5856 - accuracy: 0.6671 - val_loss: 0.6750 - val_accuracy: 0.6077\n",
      "Epoch 78/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5824 - accuracy: 0.6713 - val_loss: 0.6871 - val_accuracy: 0.5793\n",
      "Epoch 79/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5831 - accuracy: 0.6658 - val_loss: 0.6757 - val_accuracy: 0.5893\n",
      "Epoch 80/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5815 - accuracy: 0.6729 - val_loss: 0.6755 - val_accuracy: 0.6043\n",
      "Epoch 81/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5778 - accuracy: 0.6717 - val_loss: 0.6846 - val_accuracy: 0.6043\n",
      "Epoch 82/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.6759 - val_loss: 0.6749 - val_accuracy: 0.5910\n",
      "Epoch 83/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5792 - accuracy: 0.6708 - val_loss: 0.6822 - val_accuracy: 0.5843\n",
      "Epoch 84/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5784 - accuracy: 0.6767 - val_loss: 0.6789 - val_accuracy: 0.5893\n",
      "Epoch 85/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.6742 - val_loss: 0.6815 - val_accuracy: 0.6127\n",
      "Epoch 86/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.6796 - val_loss: 0.6849 - val_accuracy: 0.6077\n",
      "Epoch 87/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5759 - accuracy: 0.6704 - val_loss: 0.6876 - val_accuracy: 0.5893\n",
      "Epoch 88/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5738 - accuracy: 0.6846 - val_loss: 0.6815 - val_accuracy: 0.6093\n",
      "Epoch 89/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.6754 - val_loss: 0.6790 - val_accuracy: 0.6060\n",
      "Epoch 90/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5717 - accuracy: 0.6763 - val_loss: 0.6776 - val_accuracy: 0.6060\n",
      "Epoch 91/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.6796 - val_loss: 0.6805 - val_accuracy: 0.6110\n",
      "Epoch 92/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.6867 - val_loss: 0.6824 - val_accuracy: 0.6177\n",
      "Epoch 93/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.6784 - val_loss: 0.6928 - val_accuracy: 0.5910\n",
      "Epoch 94/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.6871 - val_loss: 0.6798 - val_accuracy: 0.6043\n",
      "Epoch 95/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.6834 - val_loss: 0.6829 - val_accuracy: 0.6093\n",
      "Epoch 96/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.6792 - val_loss: 0.6843 - val_accuracy: 0.6093\n",
      "Epoch 97/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.6876 - val_loss: 0.6865 - val_accuracy: 0.6077\n",
      "Epoch 98/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.6838 - val_loss: 0.6801 - val_accuracy: 0.5910\n",
      "Epoch 99/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.6909 - val_loss: 0.6944 - val_accuracy: 0.6077\n",
      "Epoch 100/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5622 - accuracy: 0.6896 - val_loss: 0.6824 - val_accuracy: 0.6194\n",
      "Epoch 101/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5630 - accuracy: 0.6813 - val_loss: 0.6869 - val_accuracy: 0.6060\n",
      "Epoch 102/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5620 - accuracy: 0.6901 - val_loss: 0.6866 - val_accuracy: 0.6127\n",
      "Epoch 103/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5631 - accuracy: 0.6888 - val_loss: 0.6960 - val_accuracy: 0.5659\n",
      "Epoch 104/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5603 - accuracy: 0.6859 - val_loss: 0.6888 - val_accuracy: 0.5876\n",
      "Epoch 105/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5593 - accuracy: 0.6888 - val_loss: 0.6967 - val_accuracy: 0.6227\n",
      "Epoch 106/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5588 - accuracy: 0.6917 - val_loss: 0.6857 - val_accuracy: 0.5927\n",
      "Epoch 107/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5575 - accuracy: 0.6867 - val_loss: 0.6857 - val_accuracy: 0.5910\n",
      "Epoch 108/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5566 - accuracy: 0.6963 - val_loss: 0.6821 - val_accuracy: 0.6127\n",
      "Epoch 109/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5549 - accuracy: 0.6921 - val_loss: 0.6886 - val_accuracy: 0.6194\n",
      "Epoch 110/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5546 - accuracy: 0.6947 - val_loss: 0.6913 - val_accuracy: 0.6127\n",
      "Epoch 111/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5538 - accuracy: 0.7022 - val_loss: 0.6885 - val_accuracy: 0.6043\n",
      "Epoch 112/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5541 - accuracy: 0.6896 - val_loss: 0.6958 - val_accuracy: 0.6244\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5502 - accuracy: 0.6942 - val_loss: 0.7044 - val_accuracy: 0.6194\n",
      "Epoch 114/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5482 - accuracy: 0.6984 - val_loss: 0.6992 - val_accuracy: 0.6093\n",
      "Epoch 115/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5500 - accuracy: 0.6988 - val_loss: 0.6884 - val_accuracy: 0.5927\n",
      "Epoch 116/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5523 - accuracy: 0.6892 - val_loss: 0.6829 - val_accuracy: 0.6311\n",
      "Epoch 117/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5501 - accuracy: 0.6947 - val_loss: 0.6926 - val_accuracy: 0.6144\n",
      "Epoch 118/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5498 - accuracy: 0.6959 - val_loss: 0.6905 - val_accuracy: 0.6110\n",
      "Epoch 119/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5494 - accuracy: 0.6917 - val_loss: 0.6855 - val_accuracy: 0.6210\n",
      "Epoch 120/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5471 - accuracy: 0.6942 - val_loss: 0.7258 - val_accuracy: 0.5593\n",
      "Epoch 121/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5475 - accuracy: 0.6955 - val_loss: 0.6964 - val_accuracy: 0.6244\n",
      "Epoch 122/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5440 - accuracy: 0.7051 - val_loss: 0.6989 - val_accuracy: 0.6127\n",
      "Epoch 123/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5452 - accuracy: 0.6997 - val_loss: 0.6950 - val_accuracy: 0.5726\n",
      "Epoch 124/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5438 - accuracy: 0.7047 - val_loss: 0.6953 - val_accuracy: 0.5893\n",
      "Epoch 125/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5433 - accuracy: 0.6988 - val_loss: 0.6833 - val_accuracy: 0.6043\n",
      "Epoch 126/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5425 - accuracy: 0.6997 - val_loss: 0.6987 - val_accuracy: 0.6244\n",
      "Epoch 127/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5411 - accuracy: 0.7018 - val_loss: 0.6941 - val_accuracy: 0.5860\n",
      "Epoch 128/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5404 - accuracy: 0.7059 - val_loss: 0.6872 - val_accuracy: 0.6327\n",
      "Epoch 129/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5408 - accuracy: 0.7051 - val_loss: 0.6908 - val_accuracy: 0.6160\n",
      "Epoch 130/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5391 - accuracy: 0.6967 - val_loss: 0.6897 - val_accuracy: 0.6277\n",
      "Epoch 131/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5388 - accuracy: 0.7089 - val_loss: 0.6883 - val_accuracy: 0.6027\n",
      "Epoch 132/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5373 - accuracy: 0.7072 - val_loss: 0.7190 - val_accuracy: 0.6277\n",
      "Epoch 133/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5383 - accuracy: 0.7051 - val_loss: 0.6904 - val_accuracy: 0.6210\n",
      "Epoch 134/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5372 - accuracy: 0.7076 - val_loss: 0.6987 - val_accuracy: 0.5910\n",
      "Epoch 135/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5386 - accuracy: 0.7126 - val_loss: 0.6965 - val_accuracy: 0.6327\n",
      "Epoch 136/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5372 - accuracy: 0.7043 - val_loss: 0.6984 - val_accuracy: 0.6227\n",
      "Epoch 137/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5356 - accuracy: 0.7122 - val_loss: 0.7009 - val_accuracy: 0.5860\n",
      "Epoch 138/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5330 - accuracy: 0.7164 - val_loss: 0.7055 - val_accuracy: 0.5927\n",
      "Epoch 139/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5333 - accuracy: 0.7038 - val_loss: 0.6984 - val_accuracy: 0.6110\n",
      "Epoch 140/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5341 - accuracy: 0.7160 - val_loss: 0.6943 - val_accuracy: 0.5910\n",
      "Epoch 141/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5304 - accuracy: 0.7126 - val_loss: 0.6983 - val_accuracy: 0.6110\n",
      "Epoch 142/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5265 - accuracy: 0.7160 - val_loss: 0.6987 - val_accuracy: 0.6060\n",
      "Epoch 143/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5315 - accuracy: 0.7118 - val_loss: 0.7142 - val_accuracy: 0.5793\n",
      "Epoch 144/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5311 - accuracy: 0.7164 - val_loss: 0.6976 - val_accuracy: 0.5943\n",
      "Epoch 145/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5306 - accuracy: 0.7122 - val_loss: 0.7012 - val_accuracy: 0.6344\n",
      "Epoch 146/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5270 - accuracy: 0.7155 - val_loss: 0.7345 - val_accuracy: 0.5710\n",
      "Epoch 147/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5282 - accuracy: 0.7093 - val_loss: 0.7117 - val_accuracy: 0.5760\n",
      "Epoch 148/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5291 - accuracy: 0.7147 - val_loss: 0.7120 - val_accuracy: 0.5943\n",
      "Epoch 149/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5276 - accuracy: 0.7147 - val_loss: 0.7143 - val_accuracy: 0.6377\n",
      "Epoch 150/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5263 - accuracy: 0.7118 - val_loss: 0.7104 - val_accuracy: 0.5810\n",
      "Epoch 151/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5268 - accuracy: 0.7214 - val_loss: 0.7141 - val_accuracy: 0.6210\n",
      "Epoch 152/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5245 - accuracy: 0.7176 - val_loss: 0.6991 - val_accuracy: 0.6127\n",
      "Epoch 153/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5245 - accuracy: 0.7160 - val_loss: 0.7176 - val_accuracy: 0.5826\n",
      "Epoch 154/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5228 - accuracy: 0.7155 - val_loss: 0.7076 - val_accuracy: 0.5927\n",
      "Epoch 155/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5231 - accuracy: 0.7268 - val_loss: 0.7137 - val_accuracy: 0.5960\n",
      "Epoch 156/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5209 - accuracy: 0.7147 - val_loss: 0.6999 - val_accuracy: 0.6277\n",
      "Epoch 157/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5223 - accuracy: 0.7206 - val_loss: 0.7053 - val_accuracy: 0.5960\n",
      "Epoch 158/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5201 - accuracy: 0.7143 - val_loss: 0.7257 - val_accuracy: 0.5743\n",
      "Epoch 159/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5165 - accuracy: 0.7214 - val_loss: 0.7162 - val_accuracy: 0.6144\n",
      "Epoch 160/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5189 - accuracy: 0.7251 - val_loss: 0.7039 - val_accuracy: 0.6027\n",
      "Epoch 161/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5164 - accuracy: 0.7206 - val_loss: 0.7091 - val_accuracy: 0.6227\n",
      "Epoch 162/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5186 - accuracy: 0.7180 - val_loss: 0.7156 - val_accuracy: 0.5826\n",
      "Epoch 163/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5177 - accuracy: 0.7147 - val_loss: 0.7041 - val_accuracy: 0.5977\n",
      "Epoch 164/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5145 - accuracy: 0.7247 - val_loss: 0.7115 - val_accuracy: 0.6127\n",
      "Epoch 165/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5150 - accuracy: 0.7214 - val_loss: 0.7071 - val_accuracy: 0.6244\n",
      "Epoch 166/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5145 - accuracy: 0.7180 - val_loss: 0.7029 - val_accuracy: 0.6160\n",
      "Epoch 167/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5129 - accuracy: 0.7285 - val_loss: 0.7030 - val_accuracy: 0.6377\n",
      "Epoch 168/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5144 - accuracy: 0.7272 - val_loss: 0.7085 - val_accuracy: 0.6144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5145 - accuracy: 0.7285 - val_loss: 0.7088 - val_accuracy: 0.6110\n",
      "Epoch 170/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5138 - accuracy: 0.7310 - val_loss: 0.7076 - val_accuracy: 0.6093\n",
      "Epoch 171/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5097 - accuracy: 0.7281 - val_loss: 0.7042 - val_accuracy: 0.6244\n",
      "Epoch 172/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5124 - accuracy: 0.7272 - val_loss: 0.7173 - val_accuracy: 0.5826\n",
      "Epoch 173/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5104 - accuracy: 0.7293 - val_loss: 0.7128 - val_accuracy: 0.6043\n",
      "Epoch 174/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5109 - accuracy: 0.7189 - val_loss: 0.7164 - val_accuracy: 0.6160\n",
      "Epoch 175/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5088 - accuracy: 0.7302 - val_loss: 0.7096 - val_accuracy: 0.6027\n",
      "Epoch 176/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5076 - accuracy: 0.7293 - val_loss: 0.7086 - val_accuracy: 0.6260\n",
      "Epoch 177/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5076 - accuracy: 0.7277 - val_loss: 0.7133 - val_accuracy: 0.5943\n",
      "Epoch 178/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5077 - accuracy: 0.7348 - val_loss: 0.7116 - val_accuracy: 0.6110\n",
      "Epoch 179/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5075 - accuracy: 0.7272 - val_loss: 0.7228 - val_accuracy: 0.5977\n",
      "Epoch 180/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5057 - accuracy: 0.7335 - val_loss: 0.7105 - val_accuracy: 0.6110\n",
      "Epoch 181/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5048 - accuracy: 0.7277 - val_loss: 0.7079 - val_accuracy: 0.6244\n",
      "Epoch 182/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5030 - accuracy: 0.7306 - val_loss: 0.7069 - val_accuracy: 0.6227\n",
      "Epoch 183/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5052 - accuracy: 0.7306 - val_loss: 0.7073 - val_accuracy: 0.6043\n",
      "Epoch 184/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5034 - accuracy: 0.7377 - val_loss: 0.7207 - val_accuracy: 0.6010\n",
      "Epoch 185/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5034 - accuracy: 0.7322 - val_loss: 0.7145 - val_accuracy: 0.6043\n",
      "Epoch 186/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5017 - accuracy: 0.7322 - val_loss: 0.7389 - val_accuracy: 0.5943\n",
      "Epoch 187/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5002 - accuracy: 0.7339 - val_loss: 0.7254 - val_accuracy: 0.6060\n",
      "Epoch 188/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5027 - accuracy: 0.7331 - val_loss: 0.7205 - val_accuracy: 0.5960\n",
      "Epoch 189/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4995 - accuracy: 0.7406 - val_loss: 0.7094 - val_accuracy: 0.6010\n",
      "Epoch 190/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4996 - accuracy: 0.7389 - val_loss: 0.7301 - val_accuracy: 0.6027\n",
      "Epoch 191/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4997 - accuracy: 0.7368 - val_loss: 0.7108 - val_accuracy: 0.6227\n",
      "Epoch 192/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4996 - accuracy: 0.7356 - val_loss: 0.7281 - val_accuracy: 0.5993\n",
      "Epoch 193/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.5006 - accuracy: 0.7335 - val_loss: 0.7269 - val_accuracy: 0.6010\n",
      "Epoch 194/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4985 - accuracy: 0.7331 - val_loss: 0.7229 - val_accuracy: 0.6244\n",
      "Epoch 195/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4968 - accuracy: 0.7381 - val_loss: 0.7220 - val_accuracy: 0.6110\n",
      "Epoch 196/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4941 - accuracy: 0.7381 - val_loss: 0.7292 - val_accuracy: 0.5993\n",
      "Epoch 197/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4958 - accuracy: 0.7393 - val_loss: 0.7425 - val_accuracy: 0.6244\n",
      "Epoch 198/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4928 - accuracy: 0.7510 - val_loss: 0.7358 - val_accuracy: 0.6327\n",
      "Epoch 199/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4974 - accuracy: 0.7389 - val_loss: 0.7328 - val_accuracy: 0.5826\n",
      "Epoch 200/200\n",
      "2394/2394 [==============================] - 3s 1ms/step - loss: 0.4926 - accuracy: 0.7335 - val_loss: 0.7445 - val_accuracy: 0.5810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2134d46f8c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 200\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from resnets_utils import *\n",
    "# GRADED FUNCTION: identity_block\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Second component of main path (3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X\n",
    "\n",
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (2 lines)\n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], stage = 3, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [128,128,512], stage = 3, block = 'b')\n",
    "    X = identity_block(X, 3, [128,128,512], stage = 3, block = 'c')\n",
    "    X = identity_block(X, 3, [128,128,512], stage = 3, block = 'd')\n",
    "\n",
    "    # Stage 4 (6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block = 'b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block = 'c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block = 'd')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block = 'e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage = 4, block = 'f')\n",
    "\n",
    "    # Stage 5 (3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage = 5, block = 'b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage = 5, block = 'c')\n",
    "\n",
    "    # AVGPOOL (1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    #X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
    "    X = AveragePooling2D(pool_size = (1, 1), name = 'avg_pool')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 200\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "rn_model = ResNet50(input_shape = (64,64,3), classes = 2)\n",
    "rn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2578 samples, validate on 287 samples\n",
      "Epoch 1/30\n",
      "2578/2578 [==============================] - 56s 22ms/step - loss: 2.3562 - accuracy: 0.5628 - val_loss: 0.7921 - val_accuracy: 0.4634\n",
      "Epoch 2/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 1.6960 - accuracy: 0.5950 - val_loss: 0.7508 - val_accuracy: 0.4634\n",
      "Epoch 3/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 1.3315 - accuracy: 0.6078 - val_loss: 0.7076 - val_accuracy: 0.4878\n",
      "Epoch 4/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 1.1657 - accuracy: 0.6427 - val_loss: 1.1747 - val_accuracy: 0.5366\n",
      "Epoch 5/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.9344 - accuracy: 0.6947 - val_loss: 0.9761 - val_accuracy: 0.5993\n",
      "Epoch 6/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.6930 - accuracy: 0.7219 - val_loss: 0.7123 - val_accuracy: 0.7038\n",
      "Epoch 7/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.5805 - accuracy: 0.7785 - val_loss: 0.8134 - val_accuracy: 0.6864\n",
      "Epoch 8/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.6152 - accuracy: 0.7894 - val_loss: 0.6604 - val_accuracy: 0.6864\n",
      "Epoch 9/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.6295 - accuracy: 0.8080 - val_loss: 0.9253 - val_accuracy: 0.6620\n",
      "Epoch 10/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.4612 - accuracy: 0.8468 - val_loss: 1.2430 - val_accuracy: 0.6899\n",
      "Epoch 11/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.3842 - accuracy: 0.8685 - val_loss: 0.9325 - val_accuracy: 0.7073\n",
      "Epoch 12/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.3263 - accuracy: 0.8786 - val_loss: 1.1217 - val_accuracy: 0.7317\n",
      "Epoch 13/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.2758 - accuracy: 0.9073 - val_loss: 1.4187 - val_accuracy: 0.6934\n",
      "Epoch 14/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.2103 - accuracy: 0.9135 - val_loss: 1.0901 - val_accuracy: 0.7282\n",
      "Epoch 15/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.2093 - accuracy: 0.9240 - val_loss: 1.4411 - val_accuracy: 0.6237\n",
      "Epoch 16/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.2180 - accuracy: 0.9383 - val_loss: 1.0698 - val_accuracy: 0.7352\n",
      "Epoch 17/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.1572 - accuracy: 0.9379 - val_loss: 1.2596 - val_accuracy: 0.7003\n",
      "Epoch 18/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.1936 - accuracy: 0.9434 - val_loss: 1.3564 - val_accuracy: 0.7282\n",
      "Epoch 19/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.1945 - accuracy: 0.9500 - val_loss: 1.4992 - val_accuracy: 0.6655\n",
      "Epoch 20/30\n",
      "2578/2578 [==============================] - 42s 16ms/step - loss: 0.1314 - accuracy: 0.9511 - val_loss: 1.2574 - val_accuracy: 0.7247\n",
      "Epoch 21/30\n",
      "2528/2578 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9549"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2721e0363458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rn_model.fit(x_train, y_train, epochs = 30, batch_size = 32, validation_split = 0.1, verbose  =1 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
