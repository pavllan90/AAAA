{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_learn_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainwave Frequencies:\n",
    "Gamma, 30 to 50 Hz.  \n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n",
    "Delta, 0.1 to 4 Hz.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Bin Size: \n",
    "https://stackoverflow.com/questions/25735153/plotting-a-fast-fourier-transform-in-python  \n",
    "(Search for 'bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An EEG processing library:  \n",
    "https://github.com/pbashivan/EEGLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_model(batch_size = 32, num_classes = 3, epochs = 200, input_shape = (28, 28, 3)):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = (0.1, 4)\n",
    "theta = (4,8)\n",
    "alpha = (8,14)\n",
    "beta = (14,30)\n",
    "gamma = (30, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds \n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128.0\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = 100#Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = 100#Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "            \n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap, normalize = False):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "    \n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = 100#Fs * frame_duration\n",
    "    \n",
    "    print('Generating training data...')\n",
    "    \n",
    "    \n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df = df[['EEG.AF3','EEG.F7','EEG.F3','EEG.FC5','EEG.T7','EEG.P7','EEG.O1','EEG.O2','EEG.P8','EEG.T8','EEG.FC6','EEG.F4','EEG.F8','EEG.AF4']]\n",
    "        except:\n",
    "            df = genfromtxt(file, delimiter=',')\n",
    "            df = pd.DataFrame(df)\n",
    "        df.columns = range(14)\n",
    "        \n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "        \n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)#, augment=True, pca=True, std_mult=0.1, n_components=7)\n",
    "        images = np.swapaxes(images, 1, 3) \n",
    "        \n",
    "        #print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        #print(pca_.explained_variance_ratio_)\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "    print(X.shape)\n",
    "    if(normalize):\n",
    "        X_r = X[:,:,:,0].reshape((X.shape[0]*image_size, image_size))\n",
    "        X_g = X[:,:,:,1].reshape((X.shape[0]*image_size, image_size))\n",
    "        X_b = X[:,:,:,2].reshape((X.shape[0]*image_size, image_size))\n",
    "\n",
    "        X[:,:,:,0] = preprocessing.normalize(X_r).reshape((X.shape[0], X.shape[1], X.shape[2])) \n",
    "        X[:,:,:,1] = preprocessing.normalize(X_g).reshape((X.shape[0], X.shape[1], X.shape[2])) \n",
    "        X[:,:,:,2] = preprocessing.normalize(X_b).reshape((X.shape[0], X.shape[1], X.shape[2])) \n",
    "    \n",
    "        #with open('scalers_dump.pickle', 'wb') as f:\n",
    "        #    pickle.dump(scalers, f)\n",
    "    return X,np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_1_label0.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 39/398Interpolating 76/398Interpolating 116/398Interpolating 156/398Interpolating 199/398Interpolating 241/398Interpolating 281/398Interpolating 318/398Interpolating 357/398Interpolating 397/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_2_label1.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 41/398Interpolating 80/398Interpolating 118/398Interpolating 197/398Interpolating 235/398Interpolating 274/398Interpolating 314/398Interpolating 353/398Interpolating 393/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_3_label2.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 41/398Interpolating 83/398Interpolating 124/398Interpolating 164/398Interpolating 203/398Interpolating 242/398Interpolating 281/398Interpolating 320/398Interpolating 357/398Interpolating 395/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_4_label0.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 39/398Interpolating 78/398Interpolating 116/398Interpolating 195/398Interpolating 235/398Interpolating 274/398Interpolating 314/398Interpolating 354/398Interpolating 392/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_5_label1.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 40/398Interpolating 76/398Interpolating 117/398Interpolating 156/398Interpolating 196/398Interpolating 235/398Interpolating 272/398Interpolating 314/398Interpolating 355/398Interpolating 393/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/data_train_new_appr_6_label2.csv . ( 1  of  1 )\n",
      "Interpolating 398/398nterpolating 40/398Interpolating 79/398Interpolating 119/398Interpolating 161/398Interpolating 199/398Interpolating 238/398Interpolating 277/398Interpolating 316/398Interpolating 354/398Interpolating 394/398\n",
      "\n",
      "(398, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_7_label0.csv . ( 1  of  1 )\n",
      "Interpolating 332/332nterpolating 41/332Interpolating 78/332Interpolating 119/332Interpolating 160/332Interpolating 199/332Interpolating 238/332Interpolating 276/332Interpolating 317/332\n",
      "\n",
      "(332, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_8_label1.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 35/335Interpolating 75/335Interpolating 116/335Interpolating 156/335Interpolating 196/335Interpolating 237/335Interpolating 277/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_9_label2.csv . ( 1  of  1 )\n",
      "Interpolating 336/336nterpolating 41/336Interpolating 81/336Interpolating 120/336Interpolating 160/336Interpolating 198/336Interpolating 237/336Interpolating 275/336Interpolating 313/336\n",
      "\n",
      "(336, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_10_label0.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 75/335Interpolating 113/335Interpolating 152/335Interpolating 190/335Interpolating 230/335Interpolating 264/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_11_label1.csv . ( 1  of  1 )\n",
      "Interpolating 339/339nterpolating 41/339Interpolating 80/339Interpolating 118/339Interpolating 158/339Interpolating 193/339Interpolating 232/339Interpolating 272/339Interpolating 313/339\n",
      "\n",
      "(339, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_12_label2.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 41/335Interpolating 79/335Interpolating 119/335Interpolating 160/335Interpolating 197/335Interpolating 238/335Interpolating 280/335Interpolating 320/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_13_label0.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 39/335Interpolating 78/335Interpolating 118/335Interpolating 157/335Interpolating 198/335Interpolating 237/335Interpolating 276/335Interpolating 301/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_14_label1.csv . ( 1  of  1 )\n",
      "Interpolating 337/337nterpolating 41/337Interpolating 79/337Interpolating 159/337Interpolating 197/337Interpolating 237/337Interpolating 278/337Interpolating 320/337\n",
      "\n",
      "(337, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_15_label2.csv . ( 1  of  1 )\n",
      "Interpolating 336/336nterpolating 40/336Interpolating 79/336Interpolating 118/336Interpolating 154/336Interpolating 195/336Interpolating 233/336Interpolating 272/336Interpolating 311/336\n",
      "\n",
      "(336, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_16_label0.csv . ( 1  of  1 )\n",
      "Interpolating 339/339nterpolating 41/339Interpolating 79/339Interpolating 119/339Interpolating 159/339Interpolating 238/339Interpolating 279/339Interpolating 321/339\n",
      "\n",
      "(339, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_17_label1.csv . ( 1  of  1 )\n",
      "Interpolating 338/338nterpolating 42/338Interpolating 79/338Interpolating 119/338Interpolating 159/338Interpolating 201/338Interpolating 283/338Interpolating 325/338\n",
      "\n",
      "(338, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_18_label2.csv . ( 1  of  1 )\n",
      "Interpolating 334/334nterpolating 40/334Interpolating 79/334Interpolating 152/334Interpolating 190/334Interpolating 227/334Interpolating 301/334\n",
      "\n",
      "(334, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_19_label0.csv . ( 1  of  1 )\n",
      "Interpolating 333/333nterpolating 42/333Interpolating 81/333Interpolating 119/333Interpolating 160/333Interpolating 198/333Interpolating 238/333Interpolating 276/333Interpolating 311/333\n",
      "\n",
      "(333, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_20_label1.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 36/335Interpolating 76/335Interpolating 114/335Interpolating 148/335Interpolating 250/335Interpolating 287/335Interpolating 325/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_21_label2.csv . ( 1  of  1 )\n",
      "Interpolating 333/333nterpolating 39/333Interpolating 80/333Interpolating 118/333Interpolating 158/333Interpolating 196/333Interpolating 234/333Interpolating 273/333Interpolating 315/333\n",
      "\n",
      "(333, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_22_label0.csv . ( 1  of  1 )\n",
      "Interpolating 335/335nterpolating 42/335Interpolating 80/335Interpolating 119/335Interpolating 159/335Interpolating 198/335Interpolating 236/335Interpolating 275/335Interpolating 315/335\n",
      "\n",
      "(335, 28, 28, 3)\n",
      "Y: [1. 0. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_23_label1.csv . ( 1  of  1 )\n",
      "Interpolating 337/337nterpolating 42/337Interpolating 82/337Interpolating 122/337Interpolating 164/337Interpolating 202/337Interpolating 243/337Interpolating 285/337Interpolating 324/337\n",
      "\n",
      "(337, 28, 28, 3)\n",
      "Y: [0. 1. 0.]\n",
      "\n",
      "Generating training data...\n",
      "Processing session:  data/3_labels/Data_new_24_label2.csv . ( 1  of  1 )\n",
      "Interpolating 337/337nterpolating 39/337Interpolating 77/337Interpolating 117/337Interpolating 157/337Interpolating 199/337Interpolating 237/337Interpolating 277/337Interpolating 314/337\n",
      "\n",
      "(337, 28, 28, 3)\n",
      "Y: [0. 0. 1.]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "image_size = 28\n",
    "frame_duration = 0.78\n",
    "overlap = 0.5\n",
    "num_classes = 3\n",
    "\n",
    "#file_names = ['data/data_train_new_appr_1_label1.csv',\n",
    "#              'data/data_train_new_appr_2_label0.csv',\n",
    "#              'data/data_train_new_appr_3_label1.csv',\n",
    "#              'data/data_train_new_appr_4_label0.csv',\n",
    "#              'data/data_train_new_appr_6_label1.csv',\n",
    "#              'data/data_train_new_appr_5_label0.csv',\n",
    "#              'data/data_train_new_appr_8_label1.csv',\n",
    "#              'data/data_train_new_appr_7_label0.csv',\n",
    "#              'data/data_train_new_appr_10_label1.csv',\n",
    "#              'data/data_train_new_appr_9_label0.csv',\n",
    "#              'data/data_train_new_appr_12_label1.csv',\n",
    "#              'data/data_train_new_appr_11_label0.csv',\n",
    "#              'data/data_train_new_appr_14_label1.csv',\n",
    "#              'data/data_train_new_appr_13_label0.csv',\n",
    "#              'data/data_train_new_appr_15_label1.csv',\n",
    "#              'data/data_train_new_appr_16_label0.csv',\n",
    "#              'data/data_train_new_appr_17_label1.csv',\n",
    "#              'data/data_train_new_appr_18_label0.csv',\n",
    "#              'data/data_train_new_appr_19_label1.csv',\n",
    "#              'data/data_train_new_appr_20_label0.csv'\n",
    "#              ]\n",
    "#    file_names_good = ['data/data_train_new_appr_10_label1.csv',  good rather\n",
    "#                  'data/data_train_new_appr_9_label0.csv',\n",
    "#                  'data/data_train_new_appr_12_label1.csv',\n",
    "#                  'data/data_train_new_appr_11_label0.csv',\n",
    "#                  'data/data_train_new_appr_14_label1.csv',\n",
    "#                  'data/data_train_new_appr_13_label0.csv',\n",
    "#                  'data/data_train_new_appr_21_label1.csv',\n",
    "#                  'data/data_train_new_appr_22_label0.csv', \n",
    "#                  'data/data_train_new_appr_23_label1.csv',\n",
    "#                  'data/data_train_new_appr_24_label0.csv' ,\n",
    "#                       'data/data_train_new_appr_27_label1.csv',\n",
    "#                      'data/data_train_new_appr_28_label0.csv']\n",
    "#labels = [1,0,1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,  1, 0, 1, 0]\n",
    "#labels_good = [1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "#file_names_good = ['data/3_labels/data_train_new_appr_1_label0.csv',\n",
    "#                  'data/3_labels/data_train_new_appr_2_label1.csv',\n",
    "#                  'data/3_labels/data_train_new_appr_3_label2.csv',\n",
    "#                  'data/3_labels/data_train_new_appr_4_label0.csv',\n",
    "#                  'data/3_labels/data_train_new_appr_5_label1.csv',\n",
    "#                  'data/3_labels/data_train_new_appr_6_label2.csv']\n",
    "file_names_good = ['data/3_labels/data_train_new_appr_1_label0.csv',\n",
    "                  'data/3_labels/data_train_new_appr_2_label1.csv',\n",
    "                  'data/3_labels/data_train_new_appr_3_label2.csv',\n",
    "                  'data/3_labels/data_train_new_appr_4_label0.csv',\n",
    "                  'data/3_labels/data_train_new_appr_5_label1.csv',\n",
    "                  'data/3_labels/data_train_new_appr_6_label2.csv',\n",
    "                  'data/3_labels/Data_new_7_label0.csv',\n",
    "                  'data/3_labels/Data_new_8_label1.csv',\n",
    "                  'data/3_labels/Data_new_9_label2.csv',\n",
    "                  'data/3_labels/Data_new_10_label0.csv',\n",
    "                  'data/3_labels/Data_new_11_label1.csv',\n",
    "                  'data/3_labels/Data_new_12_label2.csv',\n",
    "                  'data/3_labels/Data_new_13_label0.csv',\n",
    "                  'data/3_labels/Data_new_14_label1.csv',\n",
    "                  'data/3_labels/Data_new_15_label2.csv',\n",
    "                  'data/3_labels/Data_new_16_label0.csv',\n",
    "                  'data/3_labels/Data_new_17_label1.csv',\n",
    "                  'data/3_labels/Data_new_18_label2.csv',\n",
    "                  'data/3_labels/Data_new_19_label0.csv',\n",
    "                  'data/3_labels/Data_new_20_label1.csv',\n",
    "                  'data/3_labels/Data_new_21_label2.csv',\n",
    "                  'data/3_labels/Data_new_22_label0.csv',\n",
    "                  'data/3_labels/Data_new_23_label1.csv',\n",
    "                  'data/3_labels/Data_new_24_label2.csv']\n",
    "labels_good = [0,1,2,0,1,2,0,1,2,0,1,2,0,1,2,0,1,2,0,1,2,0,1,2]\n",
    "X_transformed_list = []\n",
    "y_transformed_list = []\n",
    "for f_name, lbl in zip(file_names_good, labels_good):\n",
    "    X, y = make_data_pipeline([f_name],[lbl],image_size,frame_duration,overlap, normalize = False)\n",
    "    X = X.astype('float32')\n",
    "    y = keras.utils.to_categorical(y, num_classes)\n",
    "    X_transformed_list.append(X)\n",
    "    y_transformed_list.append(y)\n",
    "    print(\"Y: {}\\n\".format(y[0]))\n",
    "X_transformed_list_np = np.array(X_transformed_list)\n",
    "y_transformed_list_np = np.array(y_transformed_list)\n",
    "X_transformed_list_np.shape\n",
    "\n",
    "\n",
    "\n",
    "#X = tx[:].reshape((tx.shape[1]*tx.shape[0], 40, 40, 5))\n",
    "#y = ty[:].reshape((ty.shape[1]*ty.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6041, 28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23720916c08>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_transformed_list_np = np.array(X_transformed_list)[6:]\n",
    "y_transformed_list_np = np.array(y_transformed_list)[6:]\n",
    "\n",
    "X_transformed_list_simp = np.array(X_transformed_list)[6:]\n",
    "y_transformed_list_simp = np.array(X_transformed_list)[6:]\n",
    "\n",
    "whole = np.concatenate((X_transformed_list_np), axis = 0)\n",
    "\n",
    "#X_transformed_list_np = (X_transformed_list_np-whole.min())/(whole.max()-whole.min())\n",
    "\n",
    "print(whole.shape)\n",
    "\n",
    "whole = np.concatenate((X_transformed_list_np[:]), axis = 0)\n",
    "mean = np.sum(whole, axis = 0)/whole.shape[0]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(2,4, figsize = (16,16))\n",
    "axarr[0][0].set_title('Average')\n",
    "axarr[0][0].imshow(mean)\n",
    "axarr[0][1].set_title('Class 0')\n",
    "axarr[0][1].imshow(X_transformed_list_np[0][200])\n",
    "axarr[0][2].set_title('Class 1')\n",
    "axarr[0][2].imshow(X_transformed_list_np[1][200])\n",
    "axarr[0][3].set_title('Class 2')\n",
    "axarr[0][3].imshow(X_transformed_list_np[2][200])\n",
    "#\n",
    "\n",
    "for i in range(X_transformed_list_np.shape[0]):\n",
    "    X_transformed_list_np[i] = X_transformed_list_np[i] - mean\n",
    "\n",
    "axarr[1][0].set_title('Average')\n",
    "axarr[1][0].imshow(mean)\n",
    "axarr[1][1].set_title('Class 0 (minus mean)')\n",
    "axarr[1][1].imshow(X_transformed_list_np[0][200])\n",
    "axarr[1][2].set_title('Class 1 (minus mean)')\n",
    "axarr[1][2].imshow((X_transformed_list_np[1][200]))\n",
    "axarr[1][3].set_title('Class 2 (minus mean)')\n",
    "axarr[1][3].imshow((X_transformed_list_np[2][200]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2] [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[3, 4, 5] [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[6, 7, 8] [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[9, 10, 11] [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17]\n",
      "[12, 13, 14] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17]\n",
      "[15, 16, 17] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "\n",
      "Train on 5038 samples, validate on 1003 samples\n",
      "Epoch 1/200\n",
      "5038/5038 [==============================] - 3s 511us/step - loss: 1.1026 - accuracy: 0.3261 - val_loss: 1.1038 - val_accuracy: 0.3340\n",
      "Epoch 2/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 1.0979 - accuracy: 0.3418 - val_loss: 1.1039 - val_accuracy: 0.3589\n",
      "Epoch 3/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 1.0958 - accuracy: 0.3620 - val_loss: 1.1102 - val_accuracy: 0.3509\n",
      "Epoch 4/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 1.0883 - accuracy: 0.3684 - val_loss: 1.1077 - val_accuracy: 0.3639\n",
      "Epoch 5/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 1.0809 - accuracy: 0.3742 - val_loss: 1.1026 - val_accuracy: 0.3629\n",
      "Epoch 6/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 1.0732 - accuracy: 0.3990 - val_loss: 1.1244 - val_accuracy: 0.3370\n",
      "Epoch 7/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 1.0667 - accuracy: 0.3982 - val_loss: 1.1271 - val_accuracy: 0.3739\n",
      "Epoch 8/200\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 1.0507 - accuracy: 0.4186 - val_loss: 1.1255 - val_accuracy: 0.3569\n",
      "Epoch 9/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 1.0387 - accuracy: 0.4363 - val_loss: 1.1229 - val_accuracy: 0.3639\n",
      "Epoch 10/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 1.0275 - accuracy: 0.4585 - val_loss: 1.1188 - val_accuracy: 0.3390\n",
      "Epoch 11/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 1.0176 - accuracy: 0.4750 - val_loss: 1.1526 - val_accuracy: 0.3310\n",
      "Epoch 12/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 1.0077 - accuracy: 0.4823 - val_loss: 1.1431 - val_accuracy: 0.3549\n",
      "Epoch 13/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 1.0017 - accuracy: 0.4990 - val_loss: 1.1395 - val_accuracy: 0.3549\n",
      "Epoch 14/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9943 - accuracy: 0.4960 - val_loss: 1.1261 - val_accuracy: 0.3739\n",
      "Epoch 15/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9890 - accuracy: 0.5046 - val_loss: 1.1225 - val_accuracy: 0.3719\n",
      "Epoch 16/200\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.9784 - accuracy: 0.5105 - val_loss: 1.1370 - val_accuracy: 0.3639\n",
      "Epoch 17/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9749 - accuracy: 0.5117 - val_loss: 1.1291 - val_accuracy: 0.3789\n",
      "Epoch 18/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9713 - accuracy: 0.5189 - val_loss: 1.1396 - val_accuracy: 0.3958\n",
      "Epoch 19/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9665 - accuracy: 0.5208 - val_loss: 1.1745 - val_accuracy: 0.3789\n",
      "Epoch 20/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9601 - accuracy: 0.5254 - val_loss: 1.1520 - val_accuracy: 0.3799\n",
      "Epoch 21/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9577 - accuracy: 0.5204 - val_loss: 1.1951 - val_accuracy: 0.3509\n",
      "Epoch 22/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9508 - accuracy: 0.5363 - val_loss: 1.1605 - val_accuracy: 0.3789\n",
      "Epoch 23/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9501 - accuracy: 0.5353 - val_loss: 1.2369 - val_accuracy: 0.3619\n",
      "Epoch 24/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9438 - accuracy: 0.5355 - val_loss: 1.1868 - val_accuracy: 0.3559\n",
      "Epoch 25/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.9412 - accuracy: 0.5369 - val_loss: 1.2053 - val_accuracy: 0.3609\n",
      "Epoch 26/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9379 - accuracy: 0.5397 - val_loss: 1.1903 - val_accuracy: 0.3729\n",
      "Epoch 27/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9327 - accuracy: 0.5373 - val_loss: 1.1987 - val_accuracy: 0.3958\n",
      "Epoch 28/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.9305 - accuracy: 0.5439 - val_loss: 1.2329 - val_accuracy: 0.3769\n",
      "Epoch 29/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9252 - accuracy: 0.5574 - val_loss: 1.2149 - val_accuracy: 0.3609\n",
      "Epoch 30/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9250 - accuracy: 0.5504 - val_loss: 1.1935 - val_accuracy: 0.3779\n",
      "Epoch 31/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9196 - accuracy: 0.5574 - val_loss: 1.2495 - val_accuracy: 0.3868\n",
      "Epoch 32/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.9165 - accuracy: 0.5584 - val_loss: 1.2005 - val_accuracy: 0.3878\n",
      "Epoch 33/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9180 - accuracy: 0.5486 - val_loss: 1.2712 - val_accuracy: 0.3639\n",
      "Epoch 34/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9102 - accuracy: 0.5599 - val_loss: 1.2170 - val_accuracy: 0.3699\n",
      "Epoch 35/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.9094 - accuracy: 0.5715 - val_loss: 1.2459 - val_accuracy: 0.3769\n",
      "Epoch 36/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9076 - accuracy: 0.5641 - val_loss: 1.3144 - val_accuracy: 0.3819\n",
      "Epoch 37/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.9052 - accuracy: 0.5675 - val_loss: 1.2251 - val_accuracy: 0.4028\n",
      "Epoch 38/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.9024 - accuracy: 0.5651 - val_loss: 1.2533 - val_accuracy: 0.3838\n",
      "Epoch 39/200\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.9026 - accuracy: 0.5724 - val_loss: 1.3820 - val_accuracy: 0.3629\n",
      "Epoch 40/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8971 - accuracy: 0.5695 - val_loss: 1.2993 - val_accuracy: 0.4008\n",
      "Epoch 41/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8956 - accuracy: 0.5740 - val_loss: 1.2724 - val_accuracy: 0.3848\n",
      "Epoch 42/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8902 - accuracy: 0.5770 - val_loss: 1.2569 - val_accuracy: 0.3679\n",
      "Epoch 43/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8909 - accuracy: 0.5782 - val_loss: 1.3102 - val_accuracy: 0.3589\n",
      "Epoch 44/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8897 - accuracy: 0.5784 - val_loss: 1.2692 - val_accuracy: 0.3759\n",
      "Epoch 45/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8871 - accuracy: 0.5756 - val_loss: 1.3804 - val_accuracy: 0.3669\n",
      "Epoch 46/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8864 - accuracy: 0.5818 - val_loss: 1.3657 - val_accuracy: 0.4068\n",
      "Epoch 47/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8825 - accuracy: 0.5881 - val_loss: 1.4078 - val_accuracy: 0.3858\n",
      "Epoch 48/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8784 - accuracy: 0.5820 - val_loss: 1.3225 - val_accuracy: 0.3599\n",
      "Epoch 49/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8760 - accuracy: 0.5907 - val_loss: 1.3279 - val_accuracy: 0.3928\n",
      "Epoch 50/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8736 - accuracy: 0.5907 - val_loss: 1.4008 - val_accuracy: 0.3460\n",
      "Epoch 51/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8766 - accuracy: 0.5867 - val_loss: 1.3236 - val_accuracy: 0.3749\n",
      "Epoch 52/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8703 - accuracy: 0.5905 - val_loss: 1.4438 - val_accuracy: 0.3908\n",
      "Epoch 53/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8721 - accuracy: 0.5931 - val_loss: 1.3161 - val_accuracy: 0.3699\n",
      "Epoch 54/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8687 - accuracy: 0.5979 - val_loss: 1.3490 - val_accuracy: 0.3679\n",
      "Epoch 55/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8697 - accuracy: 0.5949 - val_loss: 1.3486 - val_accuracy: 0.3609\n",
      "Epoch 56/200\n",
      "5038/5038 [==============================] - 2s 434us/step - loss: 0.8632 - accuracy: 0.6098 - val_loss: 1.4347 - val_accuracy: 0.4028\n",
      "Epoch 57/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8635 - accuracy: 0.6000 - val_loss: 1.3520 - val_accuracy: 0.3838\n",
      "Epoch 58/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8580 - accuracy: 0.6006 - val_loss: 1.3575 - val_accuracy: 0.3549\n",
      "Epoch 59/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8581 - accuracy: 0.6038 - val_loss: 1.4502 - val_accuracy: 0.3659\n",
      "Epoch 60/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8536 - accuracy: 0.6086 - val_loss: 1.4188 - val_accuracy: 0.3868\n",
      "Epoch 61/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8551 - accuracy: 0.6022 - val_loss: 1.3718 - val_accuracy: 0.3888\n",
      "Epoch 62/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8513 - accuracy: 0.6175 - val_loss: 1.3553 - val_accuracy: 0.3679\n",
      "Epoch 63/200\n",
      "5038/5038 [==============================] - 2s 453us/step - loss: 0.8503 - accuracy: 0.6090 - val_loss: 1.4090 - val_accuracy: 0.4068\n",
      "Epoch 64/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8488 - accuracy: 0.6106 - val_loss: 1.3593 - val_accuracy: 0.3629\n",
      "Epoch 65/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8486 - accuracy: 0.6125 - val_loss: 1.4455 - val_accuracy: 0.3868\n",
      "Epoch 66/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8488 - accuracy: 0.6110 - val_loss: 1.3461 - val_accuracy: 0.3739\n",
      "Epoch 67/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8438 - accuracy: 0.6203 - val_loss: 1.4777 - val_accuracy: 0.3888\n",
      "Epoch 68/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8424 - accuracy: 0.6151 - val_loss: 1.4190 - val_accuracy: 0.3629\n",
      "Epoch 69/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8413 - accuracy: 0.6183 - val_loss: 1.4716 - val_accuracy: 0.3978\n",
      "Epoch 70/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8391 - accuracy: 0.6197 - val_loss: 1.5179 - val_accuracy: 0.3739\n",
      "Epoch 71/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8374 - accuracy: 0.6181 - val_loss: 1.3808 - val_accuracy: 0.3819\n",
      "Epoch 72/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8339 - accuracy: 0.6278 - val_loss: 1.4302 - val_accuracy: 0.3539\n",
      "Epoch 73/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8353 - accuracy: 0.6233 - val_loss: 1.5707 - val_accuracy: 0.3898\n",
      "Epoch 74/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8325 - accuracy: 0.6237 - val_loss: 1.4444 - val_accuracy: 0.4008\n",
      "Epoch 75/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.8337 - accuracy: 0.6209 - val_loss: 1.4474 - val_accuracy: 0.3958\n",
      "Epoch 76/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8290 - accuracy: 0.6274 - val_loss: 1.4778 - val_accuracy: 0.3918\n",
      "Epoch 77/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8283 - accuracy: 0.6250 - val_loss: 1.4589 - val_accuracy: 0.3988\n",
      "Epoch 78/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8236 - accuracy: 0.6320 - val_loss: 1.5043 - val_accuracy: 0.3649\n",
      "Epoch 79/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8235 - accuracy: 0.6286 - val_loss: 1.5596 - val_accuracy: 0.3769\n",
      "Epoch 80/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8219 - accuracy: 0.6306 - val_loss: 1.5327 - val_accuracy: 0.3858\n",
      "Epoch 81/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8199 - accuracy: 0.6276 - val_loss: 1.5213 - val_accuracy: 0.4038\n",
      "Epoch 82/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8137 - accuracy: 0.6417 - val_loss: 1.6066 - val_accuracy: 0.3759\n",
      "Epoch 83/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8182 - accuracy: 0.6342 - val_loss: 1.5248 - val_accuracy: 0.3968\n",
      "Epoch 84/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8145 - accuracy: 0.6387 - val_loss: 1.4431 - val_accuracy: 0.3669\n",
      "Epoch 85/200\n",
      "5038/5038 [==============================] - 2s 434us/step - loss: 0.8140 - accuracy: 0.6324 - val_loss: 1.6234 - val_accuracy: 0.3938\n",
      "Epoch 86/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.8123 - accuracy: 0.6374 - val_loss: 1.4869 - val_accuracy: 0.3789\n",
      "Epoch 87/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.8090 - accuracy: 0.6372 - val_loss: 1.5167 - val_accuracy: 0.3928\n",
      "Epoch 88/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8093 - accuracy: 0.6376 - val_loss: 1.4680 - val_accuracy: 0.3908\n",
      "Epoch 89/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.8017 - accuracy: 0.6427 - val_loss: 1.5958 - val_accuracy: 0.3958\n",
      "Epoch 90/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.7975 - accuracy: 0.6520 - val_loss: 1.5069 - val_accuracy: 0.3888\n",
      "Epoch 91/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8002 - accuracy: 0.6475 - val_loss: 1.4488 - val_accuracy: 0.3868\n",
      "Epoch 92/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.8010 - accuracy: 0.6433 - val_loss: 1.6191 - val_accuracy: 0.3918\n",
      "Epoch 93/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7961 - accuracy: 0.6421 - val_loss: 1.5013 - val_accuracy: 0.3809\n",
      "Epoch 94/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7940 - accuracy: 0.6528 - val_loss: 1.7394 - val_accuracy: 0.3649\n",
      "Epoch 95/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7928 - accuracy: 0.6501 - val_loss: 1.5088 - val_accuracy: 0.4018\n",
      "Epoch 96/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7925 - accuracy: 0.6477 - val_loss: 1.4905 - val_accuracy: 0.3679\n",
      "Epoch 97/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7893 - accuracy: 0.6439 - val_loss: 1.5416 - val_accuracy: 0.4078\n",
      "Epoch 98/200\n",
      "5038/5038 [==============================] - 2s 444us/step - loss: 0.7852 - accuracy: 0.6582 - val_loss: 1.5567 - val_accuracy: 0.3988\n",
      "Epoch 99/200\n",
      "5038/5038 [==============================] - 2s 446us/step - loss: 0.7837 - accuracy: 0.6560 - val_loss: 1.5100 - val_accuracy: 0.3948\n",
      "Epoch 100/200\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.7825 - accuracy: 0.6572 - val_loss: 1.4911 - val_accuracy: 0.3789\n",
      "Epoch 101/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.7831 - accuracy: 0.6513 - val_loss: 1.6351 - val_accuracy: 0.3928\n",
      "Epoch 102/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7817 - accuracy: 0.6528 - val_loss: 1.5429 - val_accuracy: 0.3988\n",
      "Epoch 103/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7769 - accuracy: 0.6572 - val_loss: 1.7970 - val_accuracy: 0.3579\n",
      "Epoch 104/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7751 - accuracy: 0.6610 - val_loss: 1.5425 - val_accuracy: 0.3848\n",
      "Epoch 105/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7781 - accuracy: 0.6588 - val_loss: 1.5195 - val_accuracy: 0.3958\n",
      "Epoch 106/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7717 - accuracy: 0.6616 - val_loss: 1.6360 - val_accuracy: 0.4008\n",
      "Epoch 107/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7728 - accuracy: 0.6548 - val_loss: 1.4623 - val_accuracy: 0.3749\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7727 - accuracy: 0.6566 - val_loss: 1.6208 - val_accuracy: 0.4018\n",
      "Epoch 109/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7680 - accuracy: 0.6612 - val_loss: 1.5105 - val_accuracy: 0.3938\n",
      "Epoch 110/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7650 - accuracy: 0.6663 - val_loss: 1.6374 - val_accuracy: 0.4008\n",
      "Epoch 111/200\n",
      "5038/5038 [==============================] - 2s 453us/step - loss: 0.7604 - accuracy: 0.6755 - val_loss: 1.5968 - val_accuracy: 0.3799\n",
      "Epoch 112/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7621 - accuracy: 0.6634 - val_loss: 1.5846 - val_accuracy: 0.3878\n",
      "Epoch 113/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7616 - accuracy: 0.6673 - val_loss: 1.4960 - val_accuracy: 0.3809\n",
      "Epoch 114/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7577 - accuracy: 0.6671 - val_loss: 1.6599 - val_accuracy: 0.3908\n",
      "Epoch 115/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7605 - accuracy: 0.6653 - val_loss: 1.5764 - val_accuracy: 0.4048\n",
      "Epoch 116/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.7584 - accuracy: 0.6669 - val_loss: 1.6838 - val_accuracy: 0.3759\n",
      "Epoch 117/200\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.7581 - accuracy: 0.6691 - val_loss: 1.6885 - val_accuracy: 0.4048\n",
      "Epoch 118/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7531 - accuracy: 0.6675 - val_loss: 1.6196 - val_accuracy: 0.4038\n",
      "Epoch 119/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7529 - accuracy: 0.6679 - val_loss: 1.7212 - val_accuracy: 0.3858\n",
      "Epoch 120/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7493 - accuracy: 0.6751 - val_loss: 1.5370 - val_accuracy: 0.3709\n",
      "Epoch 121/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7481 - accuracy: 0.6695 - val_loss: 1.5634 - val_accuracy: 0.3898\n",
      "Epoch 122/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7508 - accuracy: 0.6727 - val_loss: 1.6921 - val_accuracy: 0.3978\n",
      "Epoch 123/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7470 - accuracy: 0.6689 - val_loss: 1.7263 - val_accuracy: 0.4088\n",
      "Epoch 124/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7431 - accuracy: 0.6741 - val_loss: 1.6848 - val_accuracy: 0.3978\n",
      "Epoch 125/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7437 - accuracy: 0.6788 - val_loss: 1.5554 - val_accuracy: 0.3699\n",
      "Epoch 126/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7466 - accuracy: 0.6749 - val_loss: 1.5867 - val_accuracy: 0.3998\n",
      "Epoch 127/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7381 - accuracy: 0.6778 - val_loss: 1.6056 - val_accuracy: 0.3908\n",
      "Epoch 128/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7388 - accuracy: 0.6796 - val_loss: 1.6618 - val_accuracy: 0.3898\n",
      "Epoch 129/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7374 - accuracy: 0.6776 - val_loss: 1.5771 - val_accuracy: 0.3838\n",
      "Epoch 130/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7353 - accuracy: 0.6739 - val_loss: 1.5208 - val_accuracy: 0.3948\n",
      "Epoch 131/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7333 - accuracy: 0.6808 - val_loss: 1.6381 - val_accuracy: 0.4048\n",
      "Epoch 132/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.7317 - accuracy: 0.6790 - val_loss: 1.7088 - val_accuracy: 0.3948\n",
      "Epoch 133/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7298 - accuracy: 0.6796 - val_loss: 1.5712 - val_accuracy: 0.3958\n",
      "Epoch 134/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7319 - accuracy: 0.6816 - val_loss: 1.6193 - val_accuracy: 0.3809\n",
      "Epoch 135/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7287 - accuracy: 0.6804 - val_loss: 1.5788 - val_accuracy: 0.3789\n",
      "Epoch 136/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.7278 - accuracy: 0.6786 - val_loss: 1.6200 - val_accuracy: 0.3928\n",
      "Epoch 137/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7259 - accuracy: 0.6828 - val_loss: 1.7435 - val_accuracy: 0.3998\n",
      "Epoch 138/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7233 - accuracy: 0.6784 - val_loss: 1.8305 - val_accuracy: 0.3898\n",
      "Epoch 139/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.7233 - accuracy: 0.6820 - val_loss: 1.7065 - val_accuracy: 0.3789\n",
      "Epoch 140/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.7248 - accuracy: 0.6826 - val_loss: 1.8286 - val_accuracy: 0.3978\n",
      "Epoch 141/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7152 - accuracy: 0.6876 - val_loss: 1.6653 - val_accuracy: 0.3829\n",
      "Epoch 142/200\n",
      "5038/5038 [==============================] - 2s 432us/step - loss: 0.7167 - accuracy: 0.6892 - val_loss: 1.6807 - val_accuracy: 0.4028\n",
      "Epoch 143/200\n",
      "5038/5038 [==============================] - 2s 434us/step - loss: 0.7149 - accuracy: 0.6878 - val_loss: 1.7651 - val_accuracy: 0.3799\n",
      "Epoch 144/200\n",
      "5038/5038 [==============================] - 2s 432us/step - loss: 0.7133 - accuracy: 0.6868 - val_loss: 1.6332 - val_accuracy: 0.3868\n",
      "Epoch 145/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.7182 - accuracy: 0.6878 - val_loss: 1.7073 - val_accuracy: 0.4028\n",
      "Epoch 146/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7137 - accuracy: 0.6878 - val_loss: 1.7670 - val_accuracy: 0.3848\n",
      "Epoch 147/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7114 - accuracy: 0.6894 - val_loss: 1.7008 - val_accuracy: 0.3988\n",
      "Epoch 148/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7049 - accuracy: 0.6915 - val_loss: 1.6990 - val_accuracy: 0.3908\n",
      "Epoch 149/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7084 - accuracy: 0.6965 - val_loss: 1.6132 - val_accuracy: 0.3908\n",
      "Epoch 150/200\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7079 - accuracy: 0.6917 - val_loss: 1.6332 - val_accuracy: 0.3928\n",
      "Epoch 151/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7089 - accuracy: 0.6921 - val_loss: 1.7243 - val_accuracy: 0.3799\n",
      "Epoch 152/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7037 - accuracy: 0.6909 - val_loss: 1.7167 - val_accuracy: 0.3978\n",
      "Epoch 153/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.7018 - accuracy: 0.6981 - val_loss: 1.7071 - val_accuracy: 0.3938\n",
      "Epoch 154/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.7045 - accuracy: 0.6937 - val_loss: 1.6616 - val_accuracy: 0.3779\n",
      "Epoch 155/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6985 - accuracy: 0.6925 - val_loss: 1.7467 - val_accuracy: 0.3888\n",
      "Epoch 156/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6971 - accuracy: 0.7009 - val_loss: 1.6373 - val_accuracy: 0.3938\n",
      "Epoch 157/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6954 - accuracy: 0.6919 - val_loss: 1.7335 - val_accuracy: 0.3868\n",
      "Epoch 158/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6961 - accuracy: 0.6955 - val_loss: 1.7279 - val_accuracy: 0.3938\n",
      "Epoch 159/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6937 - accuracy: 0.6959 - val_loss: 1.7240 - val_accuracy: 0.3819\n",
      "Epoch 160/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6911 - accuracy: 0.6941 - val_loss: 1.7016 - val_accuracy: 0.3978\n",
      "Epoch 161/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6969 - accuracy: 0.6991 - val_loss: 1.7353 - val_accuracy: 0.3968\n",
      "Epoch 162/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6921 - accuracy: 0.6947 - val_loss: 1.7239 - val_accuracy: 0.4058\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6888 - accuracy: 0.7019 - val_loss: 1.7443 - val_accuracy: 0.3809\n",
      "Epoch 164/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6885 - accuracy: 0.7076 - val_loss: 1.7998 - val_accuracy: 0.3978\n",
      "Epoch 165/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6869 - accuracy: 0.7023 - val_loss: 1.9764 - val_accuracy: 0.3988\n",
      "Epoch 166/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.6861 - accuracy: 0.7035 - val_loss: 1.8036 - val_accuracy: 0.3988\n",
      "Epoch 167/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6859 - accuracy: 0.7078 - val_loss: 1.7005 - val_accuracy: 0.3938\n",
      "Epoch 168/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6789 - accuracy: 0.7108 - val_loss: 1.7241 - val_accuracy: 0.4018\n",
      "Epoch 169/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.6800 - accuracy: 0.7076 - val_loss: 1.7548 - val_accuracy: 0.3898\n",
      "Epoch 170/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6793 - accuracy: 0.7044 - val_loss: 2.0056 - val_accuracy: 0.4038\n",
      "Epoch 171/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6799 - accuracy: 0.7056 - val_loss: 1.8811 - val_accuracy: 0.3759\n",
      "Epoch 172/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6761 - accuracy: 0.7062 - val_loss: 1.8813 - val_accuracy: 0.3988\n",
      "Epoch 173/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.6736 - accuracy: 0.7126 - val_loss: 1.8299 - val_accuracy: 0.4038\n",
      "Epoch 174/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6772 - accuracy: 0.7100 - val_loss: 1.8508 - val_accuracy: 0.3978\n",
      "Epoch 175/200\n",
      "5038/5038 [==============================] - 2s 432us/step - loss: 0.6762 - accuracy: 0.7102 - val_loss: 1.7492 - val_accuracy: 0.3848\n",
      "Epoch 176/200\n",
      "5038/5038 [==============================] - 2s 432us/step - loss: 0.6714 - accuracy: 0.7100 - val_loss: 1.8500 - val_accuracy: 0.4038\n",
      "Epoch 177/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6698 - accuracy: 0.7140 - val_loss: 1.7914 - val_accuracy: 0.3659\n",
      "Epoch 178/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6709 - accuracy: 0.7084 - val_loss: 1.7494 - val_accuracy: 0.3809\n",
      "Epoch 179/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6688 - accuracy: 0.7084 - val_loss: 1.8337 - val_accuracy: 0.3888\n",
      "Epoch 180/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6661 - accuracy: 0.7152 - val_loss: 1.7912 - val_accuracy: 0.3749\n",
      "Epoch 181/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.6640 - accuracy: 0.7179 - val_loss: 1.7136 - val_accuracy: 0.3968\n",
      "Epoch 182/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.6651 - accuracy: 0.7130 - val_loss: 1.9733 - val_accuracy: 0.3779\n",
      "Epoch 183/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6632 - accuracy: 0.7164 - val_loss: 1.9665 - val_accuracy: 0.4058\n",
      "Epoch 184/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6579 - accuracy: 0.7150 - val_loss: 1.8736 - val_accuracy: 0.4058\n",
      "Epoch 185/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6608 - accuracy: 0.7160 - val_loss: 1.9701 - val_accuracy: 0.3829\n",
      "Epoch 186/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6605 - accuracy: 0.7189 - val_loss: 1.9883 - val_accuracy: 0.3998\n",
      "Epoch 187/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6553 - accuracy: 0.7217 - val_loss: 1.9764 - val_accuracy: 0.4088\n",
      "Epoch 188/200\n",
      "5038/5038 [==============================] - 2s 436us/step - loss: 0.6582 - accuracy: 0.7211 - val_loss: 1.9034 - val_accuracy: 0.3928\n",
      "Epoch 189/200\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.6555 - accuracy: 0.7144 - val_loss: 1.9825 - val_accuracy: 0.3819\n",
      "Epoch 190/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6544 - accuracy: 0.7235 - val_loss: 1.9726 - val_accuracy: 0.4058\n",
      "Epoch 191/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6540 - accuracy: 0.7154 - val_loss: 1.8295 - val_accuracy: 0.3888\n",
      "Epoch 192/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6546 - accuracy: 0.7187 - val_loss: 1.7701 - val_accuracy: 0.3829\n",
      "Epoch 193/200\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6547 - accuracy: 0.7191 - val_loss: 2.2135 - val_accuracy: 0.3679\n",
      "Epoch 194/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6483 - accuracy: 0.7243 - val_loss: 2.1381 - val_accuracy: 0.4008\n",
      "Epoch 195/200\n",
      "5038/5038 [==============================] - 2s 444us/step - loss: 0.6556 - accuracy: 0.7177 - val_loss: 1.9532 - val_accuracy: 0.3858\n",
      "Epoch 196/200\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.6445 - accuracy: 0.7245 - val_loss: 1.9676 - val_accuracy: 0.4048\n",
      "Epoch 197/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6476 - accuracy: 0.7293 - val_loss: 1.9285 - val_accuracy: 0.3858\n",
      "Epoch 198/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6461 - accuracy: 0.7287 - val_loss: 2.0175 - val_accuracy: 0.3948\n",
      "Epoch 199/200\n",
      "5038/5038 [==============================] - 2s 437us/step - loss: 0.6434 - accuracy: 0.7269 - val_loss: 1.9626 - val_accuracy: 0.3579\n",
      "Epoch 200/200\n",
      "5038/5038 [==============================] - 2s 435us/step - loss: 0.6477 - accuracy: 0.7245 - val_loss: 1.9940 - val_accuracy: 0.3898\n",
      "{'test': [0, 1, 2], 'train': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20       332\n",
      "           1       0.38      0.59      0.47       335\n",
      "           2       0.48      0.42      0.44       336\n",
      "\n",
      "    accuracy                           0.39      1003\n",
      "   macro avg       0.38      0.39      0.37      1003\n",
      "weighted avg       0.38      0.39      0.37      1003\n",
      "\n",
      "\n",
      "Train on 5038 samples, validate on 1003 samples\n",
      "Epoch 1/50\n",
      "5038/5038 [==============================] - 3s 513us/step - loss: 1.0912 - accuracy: 0.3720 - val_loss: 1.1056 - val_accuracy: 0.2991\n",
      "Epoch 2/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 1.0607 - accuracy: 0.4299 - val_loss: 1.1719 - val_accuracy: 0.3599\n",
      "Epoch 3/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 1.0298 - accuracy: 0.4800 - val_loss: 1.1810 - val_accuracy: 0.3799\n",
      "Epoch 4/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 1.0045 - accuracy: 0.5030 - val_loss: 1.1688 - val_accuracy: 0.3549\n",
      "Epoch 5/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.9771 - accuracy: 0.5256 - val_loss: 1.1780 - val_accuracy: 0.3549\n",
      "Epoch 6/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9563 - accuracy: 0.5417 - val_loss: 1.1678 - val_accuracy: 0.3699\n",
      "Epoch 7/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.9351 - accuracy: 0.5500 - val_loss: 1.1660 - val_accuracy: 0.3829\n",
      "Epoch 8/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.9201 - accuracy: 0.5655 - val_loss: 1.2558 - val_accuracy: 0.3759\n",
      "Epoch 9/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.9056 - accuracy: 0.5717 - val_loss: 1.2151 - val_accuracy: 0.3569\n",
      "Epoch 10/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8923 - accuracy: 0.5792 - val_loss: 1.2969 - val_accuracy: 0.3749\n",
      "Epoch 11/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8744 - accuracy: 0.5873 - val_loss: 1.2310 - val_accuracy: 0.3769\n",
      "Epoch 12/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8637 - accuracy: 0.5996 - val_loss: 1.2704 - val_accuracy: 0.3639\n",
      "Epoch 13/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8489 - accuracy: 0.6014 - val_loss: 1.3125 - val_accuracy: 0.3689\n",
      "Epoch 14/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.8377 - accuracy: 0.6070 - val_loss: 1.3678 - val_accuracy: 0.3729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.8243 - accuracy: 0.6237 - val_loss: 1.3209 - val_accuracy: 0.3689\n",
      "Epoch 16/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8128 - accuracy: 0.6262 - val_loss: 1.3519 - val_accuracy: 0.3629\n",
      "Epoch 17/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.8039 - accuracy: 0.6318 - val_loss: 1.3052 - val_accuracy: 0.3669\n",
      "Epoch 18/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7983 - accuracy: 0.6407 - val_loss: 1.2898 - val_accuracy: 0.3729\n",
      "Epoch 19/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.7853 - accuracy: 0.6391 - val_loss: 1.3727 - val_accuracy: 0.3868\n",
      "Epoch 20/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7784 - accuracy: 0.6441 - val_loss: 1.3747 - val_accuracy: 0.3689\n",
      "Epoch 21/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7690 - accuracy: 0.6522 - val_loss: 1.4660 - val_accuracy: 0.3709\n",
      "Epoch 22/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.7610 - accuracy: 0.6536 - val_loss: 1.6331 - val_accuracy: 0.3958\n",
      "Epoch 23/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.7560 - accuracy: 0.6618 - val_loss: 1.3336 - val_accuracy: 0.3938\n",
      "Epoch 24/50\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.7458 - accuracy: 0.6673 - val_loss: 1.4187 - val_accuracy: 0.4018\n",
      "Epoch 25/50\n",
      "5038/5038 [==============================] - 2s 448us/step - loss: 0.7422 - accuracy: 0.6665 - val_loss: 1.3488 - val_accuracy: 0.3888\n",
      "Epoch 26/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.7325 - accuracy: 0.6741 - val_loss: 1.4083 - val_accuracy: 0.4018\n",
      "Epoch 27/50\n",
      "5038/5038 [==============================] - 2s 434us/step - loss: 0.7242 - accuracy: 0.6725 - val_loss: 1.4027 - val_accuracy: 0.4028\n",
      "Epoch 28/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7204 - accuracy: 0.6840 - val_loss: 1.3460 - val_accuracy: 0.4118\n",
      "Epoch 29/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7150 - accuracy: 0.6842 - val_loss: 1.4919 - val_accuracy: 0.3829\n",
      "Epoch 30/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7107 - accuracy: 0.6884 - val_loss: 1.3844 - val_accuracy: 0.4177\n",
      "Epoch 31/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.7055 - accuracy: 0.6921 - val_loss: 1.3718 - val_accuracy: 0.4028\n",
      "Epoch 32/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.6962 - accuracy: 0.6947 - val_loss: 1.4416 - val_accuracy: 0.4018\n",
      "Epoch 33/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.6918 - accuracy: 0.6967 - val_loss: 1.5226 - val_accuracy: 0.3938\n",
      "Epoch 34/50\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6910 - accuracy: 0.6993 - val_loss: 1.5084 - val_accuracy: 0.3978\n",
      "Epoch 35/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.6800 - accuracy: 0.7078 - val_loss: 1.4217 - val_accuracy: 0.4257\n",
      "Epoch 36/50\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.6779 - accuracy: 0.7044 - val_loss: 1.4142 - val_accuracy: 0.4048\n",
      "Epoch 37/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.6717 - accuracy: 0.7094 - val_loss: 1.4562 - val_accuracy: 0.4118\n",
      "Epoch 38/50\n",
      "5038/5038 [==============================] - 2s 443us/step - loss: 0.6673 - accuracy: 0.7114 - val_loss: 1.4974 - val_accuracy: 0.4217\n",
      "Epoch 39/50\n",
      "5038/5038 [==============================] - 2s 438us/step - loss: 0.6630 - accuracy: 0.7193 - val_loss: 1.5374 - val_accuracy: 0.3868\n",
      "Epoch 40/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.6611 - accuracy: 0.7152 - val_loss: 1.5998 - val_accuracy: 0.4158\n",
      "Epoch 41/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.6588 - accuracy: 0.7160 - val_loss: 1.4476 - val_accuracy: 0.4148\n",
      "Epoch 42/50\n",
      "5038/5038 [==============================] - 2s 444us/step - loss: 0.6488 - accuracy: 0.7171 - val_loss: 1.4706 - val_accuracy: 0.4118\n",
      "Epoch 43/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.6444 - accuracy: 0.7237 - val_loss: 1.6149 - val_accuracy: 0.4247\n",
      "Epoch 44/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.6440 - accuracy: 0.7209 - val_loss: 1.6077 - val_accuracy: 0.4187\n",
      "Epoch 45/50\n",
      "5038/5038 [==============================] - 2s 441us/step - loss: 0.6380 - accuracy: 0.7211 - val_loss: 1.5212 - val_accuracy: 0.4227\n",
      "Epoch 46/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.6315 - accuracy: 0.7255 - val_loss: 1.5635 - val_accuracy: 0.4158\n",
      "Epoch 47/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.6308 - accuracy: 0.7271 - val_loss: 1.8331 - val_accuracy: 0.3978\n",
      "Epoch 48/50\n",
      "5038/5038 [==============================] - 2s 440us/step - loss: 0.6307 - accuracy: 0.7293 - val_loss: 1.5629 - val_accuracy: 0.4207\n",
      "Epoch 49/50\n",
      "5038/5038 [==============================] - 2s 442us/step - loss: 0.6243 - accuracy: 0.7310 - val_loss: 1.5166 - val_accuracy: 0.4317\n",
      "Epoch 50/50\n",
      "5038/5038 [==============================] - 2s 439us/step - loss: 0.6238 - accuracy: 0.7342 - val_loss: 1.8733 - val_accuracy: 0.4008\n",
      "{'test': [0, 1, 2], 'train': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.09      0.14       332\n",
      "           1       0.37      0.77      0.50       335\n",
      "           2       0.53      0.34      0.41       336\n",
      "\n",
      "    accuracy                           0.40      1003\n",
      "   macro avg       0.41      0.40      0.35      1003\n",
      "weighted avg       0.41      0.40      0.35      1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "threshold =0\n",
    "i = 0\n",
    "batch_size = 32\n",
    "while i+3 <= len(X_transformed_list_np):\n",
    "    inds = {}\n",
    "    inds['test'] = [i, i+1, i+2]\n",
    "    inds['train'] = list(set(range(len(X_transformed_list_np)))-set(inds['test']))\n",
    "    indexes.append(inds)\n",
    "    print(inds['test'],inds['train'])\n",
    "    i+=3\n",
    "from sklearn.metrics import classification_report\n",
    "report_list = {}\n",
    "for ind in indexes:\n",
    "    if(ind['test'][0] <= threshold):\n",
    "        print()\n",
    "        X_train, X_test, y_train, y_test = np.concatenate((X_transformed_list_simp[ind['train']]), axis = 0), \\\n",
    "        np.concatenate((X_transformed_list_simp[ind['test']]), axis = 0),  \\\n",
    "        np.concatenate((y_transformed_list_np[ind['train']]), axis = 0),  \\\n",
    "        np.concatenate((y_transformed_list_np[ind['test']]), axis = 0)\n",
    "        model = get_model(epochs = 20)\n",
    "        model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=200, \n",
    "              validation_data = (X_test, y_test), shuffle = True)\n",
    "\n",
    "\n",
    "        report = classification_report(y_test.argmax(axis  = -1),   model.predict(X_test).argmax(axis = -1), target_names=['0','1', '2'])\n",
    "        print(ind)\n",
    "        print(report)\n",
    "        report_list[str(ind)] = report\n",
    "\n",
    "for ind in indexes:\n",
    "    if(ind['test'][0] <= threshold):\n",
    "        print()\n",
    "        X_train, X_test, y_train, y_test = np.concatenate((X_transformed_list_np[ind['train']]), axis = 0), \\\n",
    "        np.concatenate((X_transformed_list_np[ind['test']]), axis = 0),  \\\n",
    "        np.concatenate((y_transformed_list_np[ind['train']]), axis = 0),  \\\n",
    "        np.concatenate((y_transformed_list_np[ind['test']]), axis = 0)\n",
    "        model = get_model(epochs = 200)\n",
    "        model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=50, \n",
    "              validation_data = (X_test, y_test), shuffle = True)\n",
    "\n",
    "\n",
    "        report = classification_report(y_test.argmax(axis  = -1),   model.predict(X_test).argmax(axis = -1), target_names=['0','1', '2'])\n",
    "        print(ind)\n",
    "        print(report)\n",
    "        report_list[str(ind)+\"_meaned\"] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20       332\n",
      "           1       0.38      0.59      0.47       335\n",
      "           2       0.48      0.42      0.44       336\n",
      "\n",
      "    accuracy                           0.39      1003\n",
      "   macro avg       0.38      0.39      0.37      1003\n",
      "weighted avg       0.38      0.39      0.37      1003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.09      0.14       332\n",
      "           1       0.37      0.77      0.50       335\n",
      "           2       0.53      0.34      0.41       336\n",
      "\n",
      "    accuracy                           0.40      1003\n",
      "   macro avg       0.41      0.40      0.35      1003\n",
      "weighted avg       0.41      0.40      0.35      1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in report_list:\n",
    "    print(report_list[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_transformed_list_np[2][202]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-44180ad3b778>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown Skill'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed_list_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed_list_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Two subplots, the axes array is 1-d\n",
    "f, axarr = plt.subplots(2,2, figsize = (8,8))\n",
    "axarr[0][0].set_title('Known Skill')\n",
    "axarr[0][0].imshow(X_transformed_list_np[0][0])\n",
    "axarr[1][0].imshow(X_transformed_list_np[1][0])\n",
    "\n",
    "axarr[0][1].set_title('Unknown Skill')\n",
    "axarr[0][1].imshow(X_transformed_list_np[2][0])\n",
    "axarr[1][1].imshow(X_transformed_list_np[3][0])\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.01,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.concatenate((X_transformed_list_np[0:21]), axis = 0), np.concatenate((y_transformed_list_np[0:21]), axis = 0)  \n",
    "X_test, y_test = np.concatenate((X_transformed_list_np[21:]), axis = 0), np.concatenate((y_transformed_list_np[21:]), axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ace95b7e432d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "import keras\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3684 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "3684/3684 [==============================] - 2s 539us/step - loss: 1.1003 - accuracy: 0.3540 - val_loss: 1.0975 - val_accuracy: 0.3300\n",
      "Epoch 2/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 1.0754 - accuracy: 0.4121 - val_loss: 1.1162 - val_accuracy: 0.3600\n",
      "Epoch 3/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 1.0586 - accuracy: 0.4297 - val_loss: 1.0993 - val_accuracy: 0.3660\n",
      "Epoch 4/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 1.0395 - accuracy: 0.4449 - val_loss: 1.1668 - val_accuracy: 0.3240\n",
      "Epoch 5/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 1.0254 - accuracy: 0.4750 - val_loss: 1.3382 - val_accuracy: 0.3300\n",
      "Epoch 6/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 1.0159 - accuracy: 0.4878 - val_loss: 1.1711 - val_accuracy: 0.3460\n",
      "Epoch 7/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 1.0001 - accuracy: 0.5024 - val_loss: 1.1723 - val_accuracy: 0.3720\n",
      "Epoch 8/200\n",
      "3684/3684 [==============================] - 2s 428us/step - loss: 0.9872 - accuracy: 0.5217 - val_loss: 1.1435 - val_accuracy: 0.3680\n",
      "Epoch 9/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.9765 - accuracy: 0.5309 - val_loss: 1.1585 - val_accuracy: 0.3280\n",
      "Epoch 10/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.9655 - accuracy: 0.5293 - val_loss: 1.1517 - val_accuracy: 0.3320\n",
      "Epoch 11/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.9543 - accuracy: 0.5353 - val_loss: 1.2715 - val_accuracy: 0.3260\n",
      "Epoch 12/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.9489 - accuracy: 0.5480 - val_loss: 1.2545 - val_accuracy: 0.3440\n",
      "Epoch 13/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.9370 - accuracy: 0.5622 - val_loss: 1.2675 - val_accuracy: 0.3660\n",
      "Epoch 14/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.9290 - accuracy: 0.5616 - val_loss: 1.2018 - val_accuracy: 0.2760\n",
      "Epoch 15/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.9220 - accuracy: 0.5537 - val_loss: 1.2635 - val_accuracy: 0.3080\n",
      "Epoch 16/200\n",
      "3684/3684 [==============================] - 2s 409us/step - loss: 0.9156 - accuracy: 0.5673 - val_loss: 1.2074 - val_accuracy: 0.3100\n",
      "Epoch 17/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.9082 - accuracy: 0.5679 - val_loss: 1.2785 - val_accuracy: 0.3120\n",
      "Epoch 18/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.9000 - accuracy: 0.5727 - val_loss: 1.2963 - val_accuracy: 0.3000\n",
      "Epoch 19/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.8907 - accuracy: 0.5771 - val_loss: 1.2350 - val_accuracy: 0.3620\n",
      "Epoch 20/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.8890 - accuracy: 0.5790 - val_loss: 1.1966 - val_accuracy: 0.3580\n",
      "Epoch 21/200\n",
      "3684/3684 [==============================] - 2s 427us/step - loss: 0.8841 - accuracy: 0.5909 - val_loss: 1.3638 - val_accuracy: 0.3220\n",
      "Epoch 22/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.8784 - accuracy: 0.5882 - val_loss: 1.2500 - val_accuracy: 0.3060\n",
      "Epoch 23/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.8721 - accuracy: 0.5942 - val_loss: 1.5442 - val_accuracy: 0.3100\n",
      "Epoch 24/200\n",
      "3684/3684 [==============================] - 2s 407us/step - loss: 0.8666 - accuracy: 0.5890 - val_loss: 1.2169 - val_accuracy: 0.3480\n",
      "Epoch 25/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.8564 - accuracy: 0.6099 - val_loss: 1.2150 - val_accuracy: 0.3820\n",
      "Epoch 26/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.8543 - accuracy: 0.6004 - val_loss: 1.2471 - val_accuracy: 0.3120\n",
      "Epoch 27/200\n",
      "3684/3684 [==============================] - 2s 447us/step - loss: 0.8486 - accuracy: 0.6110 - val_loss: 1.4652 - val_accuracy: 0.3520\n",
      "Epoch 28/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.8435 - accuracy: 0.6078 - val_loss: 1.3468 - val_accuracy: 0.3580\n",
      "Epoch 29/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.8432 - accuracy: 0.6189 - val_loss: 1.2628 - val_accuracy: 0.3140\n",
      "Epoch 30/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.8325 - accuracy: 0.6167 - val_loss: 1.2501 - val_accuracy: 0.3180\n",
      "Epoch 31/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.8325 - accuracy: 0.6170 - val_loss: 1.2968 - val_accuracy: 0.2980\n",
      "Epoch 32/200\n",
      "3684/3684 [==============================] - 2s 422us/step - loss: 0.8304 - accuracy: 0.6205 - val_loss: 1.3003 - val_accuracy: 0.3760\n",
      "Epoch 33/200\n",
      "3684/3684 [==============================] - 2s 466us/step - loss: 0.8205 - accuracy: 0.6175 - val_loss: 1.2955 - val_accuracy: 0.3980\n",
      "Epoch 34/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.8198 - accuracy: 0.6235 - val_loss: 1.2831 - val_accuracy: 0.3500\n",
      "Epoch 35/200\n",
      "3684/3684 [==============================] - 2s 425us/step - loss: 0.8179 - accuracy: 0.6279 - val_loss: 1.3114 - val_accuracy: 0.3140\n",
      "Epoch 36/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.8067 - accuracy: 0.6338 - val_loss: 1.3867 - val_accuracy: 0.3980\n",
      "Epoch 37/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.8062 - accuracy: 0.6265 - val_loss: 1.2979 - val_accuracy: 0.4000\n",
      "Epoch 38/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.8043 - accuracy: 0.6257 - val_loss: 1.3621 - val_accuracy: 0.2560\n",
      "Epoch 39/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.7950 - accuracy: 0.6387 - val_loss: 1.5645 - val_accuracy: 0.3680\n",
      "Epoch 40/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7934 - accuracy: 0.6395 - val_loss: 1.5909 - val_accuracy: 0.3360\n",
      "Epoch 41/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.7889 - accuracy: 0.6463 - val_loss: 1.5012 - val_accuracy: 0.3580\n",
      "Epoch 42/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.7832 - accuracy: 0.6439 - val_loss: 1.5119 - val_accuracy: 0.2520\n",
      "Epoch 43/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.7826 - accuracy: 0.6515 - val_loss: 1.5338 - val_accuracy: 0.2740\n",
      "Epoch 44/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.7774 - accuracy: 0.6498 - val_loss: 1.4842 - val_accuracy: 0.3780\n",
      "Epoch 45/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.7800 - accuracy: 0.6493 - val_loss: 1.3105 - val_accuracy: 0.3040\n",
      "Epoch 46/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.7736 - accuracy: 0.6501 - val_loss: 1.3702 - val_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.7664 - accuracy: 0.6588 - val_loss: 1.2766 - val_accuracy: 0.2940\n",
      "Epoch 48/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.7653 - accuracy: 0.6520 - val_loss: 1.3390 - val_accuracy: 0.2860\n",
      "Epoch 49/200\n",
      "3684/3684 [==============================] - 2s 422us/step - loss: 0.7638 - accuracy: 0.6539 - val_loss: 1.3879 - val_accuracy: 0.3900\n",
      "Epoch 50/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.7562 - accuracy: 0.6621 - val_loss: 1.2753 - val_accuracy: 0.3060\n",
      "Epoch 51/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.7539 - accuracy: 0.6621 - val_loss: 1.4178 - val_accuracy: 0.2840\n",
      "Epoch 52/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7483 - accuracy: 0.6650 - val_loss: 1.4396 - val_accuracy: 0.3940\n",
      "Epoch 53/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.7490 - accuracy: 0.6702 - val_loss: 1.3978 - val_accuracy: 0.3080\n",
      "Epoch 54/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.7465 - accuracy: 0.6678 - val_loss: 1.4011 - val_accuracy: 0.2660\n",
      "Epoch 55/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.7367 - accuracy: 0.6691 - val_loss: 1.3797 - val_accuracy: 0.3220\n",
      "Epoch 56/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7430 - accuracy: 0.6713 - val_loss: 1.3588 - val_accuracy: 0.2920\n",
      "Epoch 57/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.7373 - accuracy: 0.6743 - val_loss: 1.6285 - val_accuracy: 0.3800\n",
      "Epoch 58/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7312 - accuracy: 0.6813 - val_loss: 1.6113 - val_accuracy: 0.3680\n",
      "Epoch 59/200\n",
      "3684/3684 [==============================] - 2s 425us/step - loss: 0.7303 - accuracy: 0.6800 - val_loss: 1.3794 - val_accuracy: 0.3580\n",
      "Epoch 60/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.7294 - accuracy: 0.6786 - val_loss: 1.6458 - val_accuracy: 0.2640\n",
      "Epoch 61/200\n",
      "3684/3684 [==============================] - 2s 429us/step - loss: 0.7265 - accuracy: 0.6789 - val_loss: 1.7163 - val_accuracy: 0.3780\n",
      "Epoch 62/200\n",
      "3684/3684 [==============================] - 2s 425us/step - loss: 0.7250 - accuracy: 0.6881 - val_loss: 1.5184 - val_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.7171 - accuracy: 0.6846 - val_loss: 1.4704 - val_accuracy: 0.3900\n",
      "Epoch 64/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7142 - accuracy: 0.6792 - val_loss: 1.3381 - val_accuracy: 0.3680\n",
      "Epoch 65/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.7153 - accuracy: 0.6873 - val_loss: 1.3044 - val_accuracy: 0.4100\n",
      "Epoch 66/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.7081 - accuracy: 0.6908 - val_loss: 1.3166 - val_accuracy: 0.3580\n",
      "Epoch 67/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.7051 - accuracy: 0.6892 - val_loss: 1.3934 - val_accuracy: 0.2940\n",
      "Epoch 68/200\n",
      "3684/3684 [==============================] - 2s 424us/step - loss: 0.7032 - accuracy: 0.6922 - val_loss: 1.7608 - val_accuracy: 0.3740\n",
      "Epoch 69/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.7027 - accuracy: 0.6906 - val_loss: 1.5195 - val_accuracy: 0.3760\n",
      "Epoch 70/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.6962 - accuracy: 0.6892 - val_loss: 1.3667 - val_accuracy: 0.3780\n",
      "Epoch 71/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6947 - accuracy: 0.7006 - val_loss: 1.5116 - val_accuracy: 0.4140\n",
      "Epoch 72/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.6954 - accuracy: 0.6971 - val_loss: 1.5101 - val_accuracy: 0.3920\n",
      "Epoch 73/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.6851 - accuracy: 0.6965 - val_loss: 1.4203 - val_accuracy: 0.3560\n",
      "Epoch 74/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.6872 - accuracy: 0.6952 - val_loss: 1.6914 - val_accuracy: 0.3660\n",
      "Epoch 75/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.6864 - accuracy: 0.7009 - val_loss: 1.4003 - val_accuracy: 0.3780\n",
      "Epoch 76/200\n",
      "3684/3684 [==============================] - 2s 428us/step - loss: 0.6814 - accuracy: 0.7058 - val_loss: 1.3255 - val_accuracy: 0.3700\n",
      "Epoch 77/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.6786 - accuracy: 0.7074 - val_loss: 1.7590 - val_accuracy: 0.3720\n",
      "Epoch 78/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.6775 - accuracy: 0.7017 - val_loss: 1.6036 - val_accuracy: 0.3960\n",
      "Epoch 79/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.6745 - accuracy: 0.7036 - val_loss: 1.6607 - val_accuracy: 0.3500\n",
      "Epoch 80/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.6703 - accuracy: 0.7112 - val_loss: 1.6840 - val_accuracy: 0.4220\n",
      "Epoch 81/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.6675 - accuracy: 0.6998 - val_loss: 1.5610 - val_accuracy: 0.3600\n",
      "Epoch 82/200\n",
      "3684/3684 [==============================] - 2s 408us/step - loss: 0.6672 - accuracy: 0.7093 - val_loss: 1.5588 - val_accuracy: 0.3480\n",
      "Epoch 83/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.6648 - accuracy: 0.7090 - val_loss: 1.5601 - val_accuracy: 0.4120\n",
      "Epoch 84/200\n",
      "3684/3684 [==============================] - 2s 437us/step - loss: 0.6660 - accuracy: 0.7120 - val_loss: 1.4372 - val_accuracy: 0.3600\n",
      "Epoch 85/200\n",
      "3684/3684 [==============================] - 2s 449us/step - loss: 0.6592 - accuracy: 0.7180 - val_loss: 1.4248 - val_accuracy: 0.3380\n",
      "Epoch 86/200\n",
      "3684/3684 [==============================] - 2s 440us/step - loss: 0.6612 - accuracy: 0.7158 - val_loss: 1.4424 - val_accuracy: 0.3800\n",
      "Epoch 87/200\n",
      "3684/3684 [==============================] - 2s 443us/step - loss: 0.6498 - accuracy: 0.7180 - val_loss: 1.6197 - val_accuracy: 0.2540\n",
      "Epoch 88/200\n",
      "3684/3684 [==============================] - 2s 424us/step - loss: 0.6551 - accuracy: 0.7169 - val_loss: 1.6792 - val_accuracy: 0.3880\n",
      "Epoch 89/200\n",
      "3684/3684 [==============================] - 2s 408us/step - loss: 0.6498 - accuracy: 0.7237 - val_loss: 1.7533 - val_accuracy: 0.3740\n",
      "Epoch 90/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.6507 - accuracy: 0.7166 - val_loss: 1.9883 - val_accuracy: 0.3260\n",
      "Epoch 91/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.6468 - accuracy: 0.7158 - val_loss: 1.6698 - val_accuracy: 0.2540\n",
      "Epoch 92/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.6508 - accuracy: 0.7177 - val_loss: 1.6043 - val_accuracy: 0.3880\n",
      "Epoch 93/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6423 - accuracy: 0.7313 - val_loss: 1.5939 - val_accuracy: 0.3780\n",
      "Epoch 94/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6385 - accuracy: 0.7253 - val_loss: 1.8059 - val_accuracy: 0.3740\n",
      "Epoch 95/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6397 - accuracy: 0.7267 - val_loss: 1.6216 - val_accuracy: 0.3520\n",
      "Epoch 96/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6367 - accuracy: 0.7302 - val_loss: 1.4929 - val_accuracy: 0.3940\n",
      "Epoch 97/200\n",
      "3684/3684 [==============================] - 2s 409us/step - loss: 0.6319 - accuracy: 0.7337 - val_loss: 1.6550 - val_accuracy: 0.2700\n",
      "Epoch 98/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.6327 - accuracy: 0.7291 - val_loss: 1.6540 - val_accuracy: 0.3620\n",
      "Epoch 99/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.6273 - accuracy: 0.7310 - val_loss: 1.9685 - val_accuracy: 0.3900\n",
      "Epoch 100/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.6298 - accuracy: 0.7288 - val_loss: 1.5932 - val_accuracy: 0.3800\n",
      "Epoch 101/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.6239 - accuracy: 0.7348 - val_loss: 1.5546 - val_accuracy: 0.2560\n",
      "Epoch 102/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.6261 - accuracy: 0.7269 - val_loss: 1.6595 - val_accuracy: 0.4000\n",
      "Epoch 103/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.6170 - accuracy: 0.7378 - val_loss: 1.6947 - val_accuracy: 0.4080\n",
      "Epoch 104/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.6205 - accuracy: 0.7326 - val_loss: 1.7346 - val_accuracy: 0.3740\n",
      "Epoch 105/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.6135 - accuracy: 0.7408 - val_loss: 1.6424 - val_accuracy: 0.3300\n",
      "Epoch 106/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.6195 - accuracy: 0.7296 - val_loss: 1.5602 - val_accuracy: 0.3640\n",
      "Epoch 107/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.6097 - accuracy: 0.7427 - val_loss: 1.4286 - val_accuracy: 0.4040\n",
      "Epoch 108/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.6038 - accuracy: 0.7432 - val_loss: 1.6475 - val_accuracy: 0.3660\n",
      "Epoch 109/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6104 - accuracy: 0.7372 - val_loss: 1.6518 - val_accuracy: 0.3600\n",
      "Epoch 110/200\n",
      "3684/3684 [==============================] - 2s 408us/step - loss: 0.6037 - accuracy: 0.7424 - val_loss: 1.6646 - val_accuracy: 0.3540\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3684/3684 [==============================] - 2s 409us/step - loss: 0.6028 - accuracy: 0.7440 - val_loss: 1.7623 - val_accuracy: 0.2620\n",
      "Epoch 112/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.6055 - accuracy: 0.7473 - val_loss: 1.5974 - val_accuracy: 0.3760\n",
      "Epoch 113/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5983 - accuracy: 0.7427 - val_loss: 1.8769 - val_accuracy: 0.2260\n",
      "Epoch 114/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.6017 - accuracy: 0.7408 - val_loss: 1.7457 - val_accuracy: 0.2820\n",
      "Epoch 115/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.5991 - accuracy: 0.7432 - val_loss: 1.5451 - val_accuracy: 0.3880\n",
      "Epoch 116/200\n",
      "3684/3684 [==============================] - 2s 409us/step - loss: 0.5957 - accuracy: 0.7473 - val_loss: 1.4751 - val_accuracy: 0.3640\n",
      "Epoch 117/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.5906 - accuracy: 0.7484 - val_loss: 1.6478 - val_accuracy: 0.3040\n",
      "Epoch 118/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5933 - accuracy: 0.7497 - val_loss: 1.8816 - val_accuracy: 0.3980\n",
      "Epoch 119/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.5932 - accuracy: 0.7579 - val_loss: 1.6442 - val_accuracy: 0.3640\n",
      "Epoch 120/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5846 - accuracy: 0.7579 - val_loss: 1.6412 - val_accuracy: 0.3060\n",
      "Epoch 121/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.5813 - accuracy: 0.7530 - val_loss: 1.6769 - val_accuracy: 0.3120\n",
      "Epoch 122/200\n",
      "3684/3684 [==============================] - 2s 409us/step - loss: 0.5855 - accuracy: 0.7557 - val_loss: 1.7429 - val_accuracy: 0.2740\n",
      "Epoch 123/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.5910 - accuracy: 0.7500 - val_loss: 1.7270 - val_accuracy: 0.3320\n",
      "Epoch 124/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.5835 - accuracy: 0.7535 - val_loss: 1.6519 - val_accuracy: 0.3780\n",
      "Epoch 125/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5745 - accuracy: 0.7595 - val_loss: 1.7285 - val_accuracy: 0.3940\n",
      "Epoch 126/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5780 - accuracy: 0.7522 - val_loss: 1.5341 - val_accuracy: 0.3120\n",
      "Epoch 127/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.5724 - accuracy: 0.7511 - val_loss: 1.7260 - val_accuracy: 0.3600\n",
      "Epoch 128/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.5713 - accuracy: 0.7584 - val_loss: 1.7598 - val_accuracy: 0.2420\n",
      "Epoch 129/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.5717 - accuracy: 0.7587 - val_loss: 1.8931 - val_accuracy: 0.3080\n",
      "Epoch 130/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5771 - accuracy: 0.7508 - val_loss: 1.9263 - val_accuracy: 0.3940\n",
      "Epoch 131/200\n",
      "3684/3684 [==============================] - 2s 408us/step - loss: 0.5706 - accuracy: 0.7576 - val_loss: 1.6470 - val_accuracy: 0.2940\n",
      "Epoch 132/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.5679 - accuracy: 0.7576 - val_loss: 1.8801 - val_accuracy: 0.3220\n",
      "Epoch 133/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5635 - accuracy: 0.7657 - val_loss: 1.8313 - val_accuracy: 0.3460\n",
      "Epoch 134/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5652 - accuracy: 0.7625 - val_loss: 1.7115 - val_accuracy: 0.3400\n",
      "Epoch 135/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.5644 - accuracy: 0.7600 - val_loss: 1.6436 - val_accuracy: 0.3600\n",
      "Epoch 136/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5581 - accuracy: 0.7628 - val_loss: 1.5001 - val_accuracy: 0.3080\n",
      "Epoch 137/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.5598 - accuracy: 0.7668 - val_loss: 1.9193 - val_accuracy: 0.3420\n",
      "Epoch 138/200\n",
      "3684/3684 [==============================] - 2s 422us/step - loss: 0.5622 - accuracy: 0.7630 - val_loss: 1.6317 - val_accuracy: 0.3280\n",
      "Epoch 139/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.5586 - accuracy: 0.7674 - val_loss: 1.6748 - val_accuracy: 0.3460\n",
      "Epoch 140/200\n",
      "3684/3684 [==============================] - 2s 433us/step - loss: 0.5545 - accuracy: 0.7717 - val_loss: 1.6571 - val_accuracy: 0.3060\n",
      "Epoch 141/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.5558 - accuracy: 0.7641 - val_loss: 1.7775 - val_accuracy: 0.2740\n",
      "Epoch 142/200\n",
      "3684/3684 [==============================] - 2s 428us/step - loss: 0.5459 - accuracy: 0.7679 - val_loss: 1.6824 - val_accuracy: 0.3580\n",
      "Epoch 143/200\n",
      "3684/3684 [==============================] - 2s 422us/step - loss: 0.5515 - accuracy: 0.7690 - val_loss: 2.0371 - val_accuracy: 0.3740\n",
      "Epoch 144/200\n",
      "3684/3684 [==============================] - 2s 423us/step - loss: 0.5501 - accuracy: 0.7660 - val_loss: 1.7814 - val_accuracy: 0.3460\n",
      "Epoch 145/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.5510 - accuracy: 0.7647 - val_loss: 1.9694 - val_accuracy: 0.2140\n",
      "Epoch 146/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5446 - accuracy: 0.7666 - val_loss: 1.8328 - val_accuracy: 0.3340\n",
      "Epoch 147/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.5474 - accuracy: 0.7706 - val_loss: 1.8414 - val_accuracy: 0.4100\n",
      "Epoch 148/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.5410 - accuracy: 0.7744 - val_loss: 2.1460 - val_accuracy: 0.3320\n",
      "Epoch 149/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5445 - accuracy: 0.7695 - val_loss: 1.6739 - val_accuracy: 0.3500\n",
      "Epoch 150/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5397 - accuracy: 0.7712 - val_loss: 1.5496 - val_accuracy: 0.3100\n",
      "Epoch 151/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.5431 - accuracy: 0.7782 - val_loss: 1.7162 - val_accuracy: 0.3600\n",
      "Epoch 152/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.5376 - accuracy: 0.7698 - val_loss: 1.6050 - val_accuracy: 0.4160\n",
      "Epoch 153/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.5270 - accuracy: 0.7831 - val_loss: 1.9415 - val_accuracy: 0.3840\n",
      "Epoch 154/200\n",
      "3684/3684 [==============================] - 2s 410us/step - loss: 0.5346 - accuracy: 0.7815 - val_loss: 2.0595 - val_accuracy: 0.3980\n",
      "Epoch 155/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.5309 - accuracy: 0.7736 - val_loss: 1.7622 - val_accuracy: 0.3800\n",
      "Epoch 156/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5266 - accuracy: 0.7761 - val_loss: 1.7965 - val_accuracy: 0.3740\n",
      "Epoch 157/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5256 - accuracy: 0.7875 - val_loss: 1.8004 - val_accuracy: 0.2340\n",
      "Epoch 158/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.5272 - accuracy: 0.7828 - val_loss: 2.1738 - val_accuracy: 0.4020\n",
      "Epoch 159/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5284 - accuracy: 0.7823 - val_loss: 1.7200 - val_accuracy: 0.3200\n",
      "Epoch 160/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5280 - accuracy: 0.7804 - val_loss: 1.7780 - val_accuracy: 0.4060\n",
      "Epoch 161/200\n",
      "3684/3684 [==============================] - 2s 411us/step - loss: 0.5263 - accuracy: 0.7850 - val_loss: 2.0521 - val_accuracy: 0.3560\n",
      "Epoch 162/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.5243 - accuracy: 0.7793 - val_loss: 1.9626 - val_accuracy: 0.4160\n",
      "Epoch 163/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5203 - accuracy: 0.7820 - val_loss: 1.8044 - val_accuracy: 0.4040\n",
      "Epoch 164/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5172 - accuracy: 0.7864 - val_loss: 2.0986 - val_accuracy: 0.3300\n",
      "Epoch 165/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5165 - accuracy: 0.7921 - val_loss: 1.5986 - val_accuracy: 0.3220\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5142 - accuracy: 0.7880 - val_loss: 2.6284 - val_accuracy: 0.3860\n",
      "Epoch 167/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.5215 - accuracy: 0.7877 - val_loss: 2.1309 - val_accuracy: 0.4340\n",
      "Epoch 168/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.5144 - accuracy: 0.7869 - val_loss: 1.8225 - val_accuracy: 0.3960\n",
      "Epoch 169/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.5133 - accuracy: 0.7896 - val_loss: 1.7961 - val_accuracy: 0.3060\n",
      "Epoch 170/200\n",
      "3684/3684 [==============================] - 2s 426us/step - loss: 0.5125 - accuracy: 0.7837 - val_loss: 1.8089 - val_accuracy: 0.2280\n",
      "Epoch 171/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.5149 - accuracy: 0.7866 - val_loss: 1.8203 - val_accuracy: 0.2920\n",
      "Epoch 172/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.5040 - accuracy: 0.7910 - val_loss: 1.5997 - val_accuracy: 0.3640\n",
      "Epoch 173/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.5009 - accuracy: 0.7902 - val_loss: 1.7459 - val_accuracy: 0.3920\n",
      "Epoch 174/200\n",
      "3684/3684 [==============================] - 2s 422us/step - loss: 0.5027 - accuracy: 0.7904 - val_loss: 1.8952 - val_accuracy: 0.2360\n",
      "Epoch 175/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.5082 - accuracy: 0.7845 - val_loss: 2.0331 - val_accuracy: 0.3500\n",
      "Epoch 176/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.5012 - accuracy: 0.7942 - val_loss: 1.6881 - val_accuracy: 0.4080\n",
      "Epoch 177/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.4982 - accuracy: 0.7921 - val_loss: 1.9104 - val_accuracy: 0.3940\n",
      "Epoch 178/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.5065 - accuracy: 0.7899 - val_loss: 1.9818 - val_accuracy: 0.3600\n",
      "Epoch 179/200\n",
      "3684/3684 [==============================] - 2s 419us/step - loss: 0.4989 - accuracy: 0.7967 - val_loss: 1.9424 - val_accuracy: 0.3780\n",
      "Epoch 180/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.4927 - accuracy: 0.7940 - val_loss: 1.9702 - val_accuracy: 0.4080\n",
      "Epoch 181/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.4942 - accuracy: 0.7951 - val_loss: 1.9475 - val_accuracy: 0.3520\n",
      "Epoch 182/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.4971 - accuracy: 0.7899 - val_loss: 1.9288 - val_accuracy: 0.3200\n",
      "Epoch 183/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.4928 - accuracy: 0.7926 - val_loss: 1.9342 - val_accuracy: 0.3080\n",
      "Epoch 184/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.4894 - accuracy: 0.8048 - val_loss: 1.9305 - val_accuracy: 0.3880\n",
      "Epoch 185/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.4910 - accuracy: 0.7959 - val_loss: 1.7462 - val_accuracy: 0.2880\n",
      "Epoch 186/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.4910 - accuracy: 0.7980 - val_loss: 1.8318 - val_accuracy: 0.2760\n",
      "Epoch 187/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.4887 - accuracy: 0.8016 - val_loss: 2.1658 - val_accuracy: 0.4040\n",
      "Epoch 188/200\n",
      "3684/3684 [==============================] - 2s 413us/step - loss: 0.4876 - accuracy: 0.7999 - val_loss: 1.9471 - val_accuracy: 0.3300\n",
      "Epoch 189/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.4865 - accuracy: 0.7989 - val_loss: 1.9658 - val_accuracy: 0.3820\n",
      "Epoch 190/200\n",
      "3684/3684 [==============================] - 2s 421us/step - loss: 0.4803 - accuracy: 0.8059 - val_loss: 1.7160 - val_accuracy: 0.2860\n",
      "Epoch 191/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.4821 - accuracy: 0.8051 - val_loss: 1.6478 - val_accuracy: 0.3360\n",
      "Epoch 192/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.4856 - accuracy: 0.7986 - val_loss: 1.7784 - val_accuracy: 0.2560\n",
      "Epoch 193/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.4884 - accuracy: 0.8016 - val_loss: 1.6959 - val_accuracy: 0.2860\n",
      "Epoch 194/200\n",
      "3684/3684 [==============================] - 2s 416us/step - loss: 0.4799 - accuracy: 0.7983 - val_loss: 2.0830 - val_accuracy: 0.3820\n",
      "Epoch 195/200\n",
      "3684/3684 [==============================] - 2s 412us/step - loss: 0.4799 - accuracy: 0.8084 - val_loss: 1.7358 - val_accuracy: 0.3300\n",
      "Epoch 196/200\n",
      "3684/3684 [==============================] - 2s 420us/step - loss: 0.4815 - accuracy: 0.8029 - val_loss: 2.0053 - val_accuracy: 0.4140\n",
      "Epoch 197/200\n",
      "3684/3684 [==============================] - 2s 414us/step - loss: 0.4764 - accuracy: 0.8086 - val_loss: 1.8425 - val_accuracy: 0.3680\n",
      "Epoch 198/200\n",
      "3684/3684 [==============================] - 2s 417us/step - loss: 0.4803 - accuracy: 0.8029 - val_loss: 2.1308 - val_accuracy: 0.4160\n",
      "Epoch 199/200\n",
      "3684/3684 [==============================] - 2s 418us/step - loss: 0.4755 - accuracy: 0.8084 - val_loss: 1.8364 - val_accuracy: 0.3940\n",
      "Epoch 200/200\n",
      "3684/3684 [==============================] - 2s 415us/step - loss: 0.4755 - accuracy: 0.8035 - val_loss: 1.8777 - val_accuracy: 0.3520\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "epochs = 200\n",
    "input_shape = (28, 28, 3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_data = (X_test, y_test), shuffle = True)\n",
    "\n",
    "model.save('80_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.62      0.44       166\n",
      "           1       0.14      0.05      0.07       167\n",
      "           2       0.49      0.39      0.43       167\n",
      "\n",
      "    accuracy                           0.35       500\n",
      "   macro avg       0.32      0.35      0.31       500\n",
      "weighted avg       0.32      0.35      0.31       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test.argmax(axis  = -1),   model.predict(X_test).argmax(axis = -1), target_names=['0','1', '2'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3438 samples, validate on 382 samples\n",
      "Epoch 1/110\n",
      "3438/3438 [==============================] - 2s 626us/step - loss: 0.9282 - accuracy: 0.5564 - val_loss: 0.9801 - val_accuracy: 0.3770\n",
      "Epoch 2/110\n",
      "3438/3438 [==============================] - 2s 461us/step - loss: 0.6803 - accuracy: 0.6172 - val_loss: 1.0249 - val_accuracy: 0.2618\n",
      "Epoch 3/110\n",
      " 544/3438 [===>..........................] - ETA: 1s - loss: 0.6203 - accuracy: 0.6489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-e1e0ade60356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m               validation_split = 0.1, class_weight = {0:1,1:1})\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 110\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "acc_row = []\n",
    "lst = []\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.01, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #x_train = x_train.astype('float32')\n",
    "    #x_test = x_test.astype('float32')\n",
    "    #x_train /= 255\n",
    "    #x_test /= 255\n",
    "\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split = 0.1, class_weight = {0:1,1:1})\n",
    "    lst.append(model.evaluate(x_test, y_test))\n",
    "    print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "24/24 [==============================] - 0s 250us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7046559453010559, 0.625]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5549999999999999\n",
      "Accuracy = 0.245\n"
     ]
    }
   ],
   "source": [
    "from test_pipeline_3 import  TestPipelineEEG\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "predictor = TestPipelineEEG(image_size = 28, frame_duration = 0.78, overlap = 0.0, model_path = '80_model.h5', normalize = True)\n",
    "data = pd.read_csv('data/data_train_new_appr_8_label0.csv')\n",
    "data.columns = range(14)\n",
    "overlap = 0.0#75\n",
    "lst = []\n",
    "i = 0\n",
    "while (i+100) <= data.shape[0]:\n",
    "    lst.append(predictor.evaluate(data.iloc[i:i+100]))\n",
    "    i = i + 100 - int(100*overlap)\n",
    "print(\"Accuracy = {}\".format(1-np.sum(lst)/len(lst)))\n",
    "i = 0\n",
    "data = pd.read_csv('data/data_train_new_appr_7_label1.csv')\n",
    "data.columns = range(14)\n",
    "lst = []\n",
    "while i+100 <= data.shape[0]:\n",
    "    lst.append(predictor.evaluate(data.iloc[i:i+100]))\n",
    "    i = i + 100 - int(100*overlap)\n",
    "print(\"Accuracy = {}\".format(np.sum(lst)/len(lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2388.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
